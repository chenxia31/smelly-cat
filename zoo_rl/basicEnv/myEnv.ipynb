{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "# Path: modelTimetable/DRL/myEnv.ipynb\n",
    "# Implementing the environment\n",
    "# Reproduction of the cartpole environment\n",
    "# \n",
    "# Discription: \n",
    "# Create a car in a two-dimensional plane with a width of 20, and the coordinates of \n",
    "# the center point are the destination of the car to reach.\n",
    "#\n",
    "# State:\n",
    "# The state of the car is represented by the coordinates of the center point of the car.(x,y)\n",
    "# Action:\n",
    "# The action of the car is represented by the speed of the car.(vx,vy)\n",
    "# Reward:\n",
    "# The reward is the distance between the car and the destination.\n",
    "# Termination:\n",
    "# The car reaches the destination.(0,0)\n",
    "# truncation:\n",
    "# The car is out of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "gymnasium is the main class that we will use to create our environment.\n",
    "\n",
    "The gymnasium class has the following methods:\n",
    "__init__(): This method is used to initialize the environment. It takes the following parameters:\n",
    "\n",
    "step(): This method is used to take an action and return the next state, reward, and whether the episode is over. \n",
    "Physical engine\n",
    "- input: action\n",
    "- output: observation, reward,terminated,truncated,info\n",
    "\n",
    "reset(): This method is used to reset the environment to its initial state.\n",
    "- input: None\n",
    "- output: observation\n",
    "\n",
    "render(): This method is used to render the environment:\n",
    "Image engine\n",
    "- input: mode(default='human','human','rgb_array','ansi','rgb_array_list)\n",
    "- output: None\n",
    "eg:gymnasium.make('CartPole-v0',render_mode='human')\n",
    "\n",
    "close(): This method is used to close the environment.\n",
    "'''\n",
    "\n",
    "class MyCar(gymnasium.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second': 2\n",
    "        }\n",
    "    def __init__(self):\n",
    "        self.target_x = 0\n",
    "        self.target_y = 0\n",
    "\n",
    "        self.size = 10\n",
    "        self.action_space = spaces.Discrete(5) # 0:stop, 1:up, 2:down, 3:left, 4:right\n",
    "        self.observation_space = spaces.Box(np.array([-self.size,-self.size]), np.array([self.size,self.size]))\n",
    "        \n",
    "        self.state = None\n",
    "        self.info = {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        # update the state by the action\n",
    "        x,y = self.state\n",
    "        if action == 0:\n",
    "            x += 0\n",
    "            y += 0\n",
    "        elif action == 1:\n",
    "            x += 0\n",
    "            y += 1\n",
    "        elif action == 2:\n",
    "            x += 0\n",
    "            y += -1\n",
    "        elif action == 3:\n",
    "            x += -1\n",
    "            y += 0\n",
    "        elif action == 4:\n",
    "            x += 1\n",
    "            y += 0\n",
    "        # the next state\n",
    "        self.state = np.array([x,y])\n",
    "        self.state = self.state.astype(np.float32)\n",
    "        reward = self._get_reward()\n",
    "        terminated = self._get_terminated()\n",
    "        terminated = bool(terminated)\n",
    "        truncated = self._get_truncated()\n",
    "        truncated = bool(truncated)\n",
    "        info = {}\n",
    "        return self.state, reward, terminated,truncated, info\n",
    "    \n",
    "    def reset(self,seed=None):\n",
    "        self.state = np.ceil(np.random.rand(2)*2*self.size)-self.size\n",
    "        self.state = self.state.astype(np.float32)\n",
    "        self.counts = 0\n",
    "        self.info = {}\n",
    "        return self.state,self.info\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        print(self.state)\n",
    "    \n",
    "    def close(self):\n",
    "        return super().close()\n",
    "\n",
    "    def _get_reward(self):\n",
    "        return -np.sqrt(self.state[0]**2+self.state[1]**2)\n",
    "    \n",
    "    def _get_terminated(self):\n",
    "        x,y = self.state\n",
    "        return x==self.target_x and y==self.target_y\n",
    "    \n",
    "    def _get_truncated(self):\n",
    "        x,y = self.state\n",
    "        return x<-self.size or x>self.size or y<-self.size or y>self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = MyCar()\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.  9.]\n",
      "[-6.  9.]\n",
      "[-6.  9.]\n",
      "[-7.  9.]\n",
      "[-7. 10.]\n",
      "[ 9. -1.]\n",
      "[ 9. -1.]\n",
      "[9. 0.]\n",
      "[9. 0.]\n",
      "[9. 1.]\n",
      "[9. 2.]\n",
      "[9. 2.]\n",
      "[8. 2.]\n",
      "[7. 2.]\n",
      "[8. 2.]\n",
      "[8. 3.]\n",
      "[7. 3.]\n",
      "[8. 3.]\n",
      "[8. 3.]\n",
      "[8. 2.]\n",
      "[8. 3.]\n",
      "[8. 4.]\n",
      "[8. 5.]\n",
      "[8. 5.]\n",
      "[7. 5.]\n",
      "[7. 5.]\n",
      "[6. 5.]\n",
      "[5. 5.]\n",
      "[5. 4.]\n",
      "[5. 4.]\n",
      "[5. 4.]\n",
      "[4. 4.]\n",
      "[4. 4.]\n",
      "[4. 4.]\n",
      "[3. 4.]\n",
      "[4. 4.]\n",
      "[4. 4.]\n",
      "[4. 5.]\n",
      "[4. 4.]\n",
      "[4. 3.]\n",
      "[4. 3.]\n",
      "[4. 4.]\n",
      "[4. 5.]\n",
      "[4. 5.]\n",
      "[5. 5.]\n",
      "[6. 5.]\n",
      "[6. 6.]\n",
      "[6. 6.]\n",
      "[5. 6.]\n",
      "[5. 6.]\n",
      "[5. 6.]\n",
      "[5. 7.]\n",
      "[6. 7.]\n",
      "[6. 8.]\n",
      "[6. 9.]\n",
      "[6. 8.]\n",
      "[6. 7.]\n",
      "[7. 7.]\n",
      "[6. 7.]\n",
      "[6. 8.]\n",
      "[6. 8.]\n",
      "[7. 8.]\n",
      "[6. 8.]\n",
      "[6. 9.]\n",
      "[ 6. 10.]\n",
      "[ 6. 10.]\n",
      "[6. 9.]\n",
      "[7. 9.]\n",
      "[6. 9.]\n",
      "[6. 9.]\n",
      "[5. 9.]\n",
      "[6. 9.]\n",
      "[5. 9.]\n",
      "[5. 8.]\n",
      "[5. 7.]\n",
      "[5. 7.]\n",
      "[5. 8.]\n",
      "[6. 8.]\n",
      "[6. 9.]\n",
      "[7. 9.]\n",
      "[7. 8.]\n",
      "[6. 8.]\n",
      "[5. 8.]\n",
      "[5. 7.]\n",
      "[4. 7.]\n",
      "[4. 8.]\n",
      "[4. 7.]\n",
      "[3. 7.]\n",
      "[4. 7.]\n",
      "[4. 6.]\n",
      "[4. 5.]\n",
      "[5. 5.]\n",
      "[4. 5.]\n",
      "[4. 4.]\n",
      "[4. 4.]\n",
      "[4. 4.]\n",
      "[4. 4.]\n",
      "[5. 4.]\n",
      "[6. 4.]\n",
      "[7. 4.]\n",
      "[6. 4.]\n",
      "[7. 4.]\n",
      "[7. 4.]\n",
      "[6. 4.]\n",
      "[6. 5.]\n",
      "[6. 5.]\n",
      "[5. 5.]\n",
      "[5. 5.]\n",
      "[6. 5.]\n",
      "[7. 5.]\n",
      "[8. 5.]\n",
      "[7. 5.]\n",
      "[7. 5.]\n",
      "[7. 5.]\n",
      "[8. 5.]\n",
      "[7. 5.]\n",
      "[8. 5.]\n",
      "[7. 5.]\n",
      "[7. 5.]\n",
      "[8. 5.]\n",
      "[8. 4.]\n",
      "[8. 3.]\n",
      "[7. 3.]\n",
      "[7. 4.]\n",
      "[7. 4.]\n",
      "[6. 4.]\n",
      "[5. 4.]\n",
      "[4. 4.]\n",
      "[5. 4.]\n",
      "[6. 4.]\n",
      "[6. 4.]\n",
      "[6. 3.]\n",
      "[6. 4.]\n",
      "[6. 5.]\n",
      "[6. 4.]\n",
      "[6. 3.]\n",
      "[6. 4.]\n",
      "[7. 4.]\n",
      "[7. 4.]\n",
      "[7. 5.]\n",
      "[7. 5.]\n",
      "[8. 5.]\n",
      "[9. 5.]\n",
      "[10.  5.]\n",
      "[9. 5.]\n",
      "[9. 6.]\n",
      "[8. 6.]\n",
      "[8. 5.]\n",
      "[7. 5.]\n",
      "[6. 5.]\n",
      "[6. 4.]\n",
      "[6. 5.]\n",
      "[6. 4.]\n",
      "[6. 3.]\n",
      "[6. 4.]\n",
      "[6. 4.]\n",
      "[6. 4.]\n",
      "[7. 4.]\n",
      "[7. 4.]\n",
      "[7. 5.]\n",
      "[7. 6.]\n",
      "[8. 6.]\n",
      "[7. 6.]\n",
      "[7. 6.]\n",
      "[7. 7.]\n",
      "[7. 6.]\n",
      "[8. 6.]\n",
      "[8. 6.]\n",
      "[8. 7.]\n",
      "[7. 7.]\n",
      "[7. 8.]\n",
      "[7. 9.]\n",
      "[ 7. 10.]\n",
      "[7. 9.]\n",
      "[7. 8.]\n",
      "[7. 9.]\n",
      "[6. 9.]\n",
      "[7. 9.]\n",
      "[7. 9.]\n",
      "[6. 9.]\n",
      "[7. 9.]\n",
      "[7. 9.]\n",
      "[ 7. 10.]\n",
      "[ 6. 10.]\n",
      "[6. 9.]\n",
      "[6. 8.]\n",
      "[7. 8.]\n",
      "[8. 8.]\n",
      "[8. 8.]\n",
      "[9. 8.]\n",
      "[10.  8.]\n",
      "[10.  7.]\n",
      "[9. 7.]\n",
      "[9. 8.]\n",
      "[10.  8.]\n",
      "[10.  8.]\n",
      "[10.  8.]\n",
      "[9. 8.]\n",
      "[9. 7.]\n",
      "[9. 8.]\n",
      "[10.  8.]\n",
      "[10.  8.]\n",
      "[9. 8.]\n",
      "[9. 9.]\n",
      "[ 9. 10.]\n",
      "[10. 10.]\n",
      "[10. 10.]\n",
      "[10. 10.]\n",
      "[10.  9.]\n",
      "[6. 3.]\n",
      "[6. 3.]\n",
      "[6. 4.]\n",
      "[5. 4.]\n",
      "[5. 5.]\n",
      "[6. 5.]\n",
      "[5. 5.]\n",
      "[5. 6.]\n",
      "[4. 6.]\n",
      "[4. 6.]\n",
      "[4. 6.]\n",
      "[4. 7.]\n",
      "[4. 7.]\n",
      "[4. 7.]\n",
      "[4. 6.]\n",
      "[4. 7.]\n",
      "[4. 8.]\n",
      "[4. 8.]\n",
      "[5. 8.]\n",
      "[5. 8.]\n",
      "[5. 7.]\n",
      "[6. 7.]\n",
      "[5. 7.]\n",
      "[4. 7.]\n",
      "[4. 8.]\n",
      "[4. 8.]\n",
      "[3. 8.]\n",
      "[2. 8.]\n",
      "[2. 8.]\n",
      "[2. 8.]\n",
      "[3. 8.]\n",
      "[3. 9.]\n",
      "[4. 9.]\n",
      "[3. 9.]\n",
      "[ 3. 10.]\n",
      "[ 3. 10.]\n",
      "[ 2. 10.]\n",
      "[-7. -7.]\n",
      "[-8. -7.]\n",
      "[-8. -8.]\n",
      "[-8. -7.]\n",
      "[-8. -6.]\n",
      "[-8. -5.]\n",
      "[-8. -6.]\n",
      "[-8. -5.]\n",
      "[-8. -4.]\n",
      "[-9. -4.]\n",
      "[-8. -4.]\n",
      "[-8. -5.]\n",
      "[-8. -4.]\n",
      "[-8. -4.]\n",
      "[-8. -3.]\n",
      "[-9. -3.]\n",
      "[-9. -3.]\n",
      "[-9. -3.]\n",
      "[-9. -4.]\n",
      "[-8. -4.]\n",
      "[-7. -4.]\n",
      "[-8. -4.]\n",
      "[-7. -4.]\n",
      "[-8. -4.]\n",
      "[-8. -3.]\n",
      "[-8. -2.]\n",
      "[-8. -3.]\n",
      "[-8. -3.]\n",
      "[-7. -3.]\n",
      "[-7. -2.]\n",
      "[-7. -1.]\n",
      "[-6. -1.]\n",
      "[-7. -1.]\n",
      "[-6. -1.]\n",
      "[-6.  0.]\n",
      "[-7.  0.]\n",
      "[-7.  0.]\n",
      "[-7. -1.]\n",
      "[-7. -2.]\n",
      "[-7. -3.]\n",
      "[-7. -4.]\n",
      "[-8. -4.]\n",
      "[-8. -5.]\n",
      "[-9. -5.]\n",
      "[-10.  -5.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "env = MyCar()\n",
    "env.reset()\n",
    "state,reward,terminated,truncated,info = env.step(env.action_space.sample())\n",
    "log = 0\n",
    "while not terminated:\n",
    "    env.render()\n",
    "    state,reward,terminated,truncated,info = env.step(env.action_space.sample())\n",
    "    if truncated:\n",
    "        env.reset()\n",
    "    log += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "`reset()` must return a tuple (obs, info)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/step/data/python-smelly-cat/zoo_rl/basicEnv/myEnv.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_rl/basicEnv/myEnv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menv_checker\u001b[39;00m \u001b[39mimport\u001b[39;00m check_env\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_rl/basicEnv/myEnv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m check_env(env, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/xclds/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:444\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    439\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    440\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYour action space has dtype \u001b[39m\u001b[39m{\u001b[39;00maction_space\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m, we recommend using np.float32 to avoid cast errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         )\n\u001b[1;32m    443\u001b[0m \u001b[39m# ============ Check the returned values ===============\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m _check_returned_values(env, observation_space, action_space)\n\u001b[1;32m    446\u001b[0m \u001b[39m# ==== Check the render method and the declared render modes ====\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_render_check:\n",
      "File \u001b[0;32m~/anaconda3/envs/xclds/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:257\u001b[0m, in \u001b[0;36m_check_returned_values\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39m# because env inherits from gymnasium.Env, we assume that `reset()` and `step()` methods exists\u001b[39;00m\n\u001b[1;32m    256\u001b[0m reset_returns \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 257\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(reset_returns, \u001b[39mtuple\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m`reset()` must return a tuple (obs, info)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(reset_returns) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`reset()` must return a tuple of size 2 (obs, info), not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(reset_returns)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m obs, info \u001b[39m=\u001b[39m reset_returns\n",
      "\u001b[0;31mAssertionError\u001b[0m: `reset()` must return a tuple (obs, info)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/step/anaconda3/envs/xclds/lib/python3.9/site-packages/ale_py/roms/__init__.py:89: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
      "  ROMS = resolve_roms()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/DQN_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.3     |\n",
      "|    ep_rew_mean      | -503     |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 9241     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7231     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | -380     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 9288     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12797    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.6     |\n",
      "|    ep_rew_mean      | -630     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 9360     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 21957    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | -432     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 9383     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27664    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 87.8     |\n",
      "|    ep_rew_mean      | -584     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 9413     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36441    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 83.4     |\n",
      "|    ep_rew_mean      | -569     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 9351     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 44785    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | -478     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 3838     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 56454    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0572   |\n",
      "|    n_updates        | 1613     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.9     |\n",
      "|    ep_rew_mean      | -93.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 61345    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0333   |\n",
      "|    n_updates        | 2836     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | -58      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 2597     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 63695    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 3423     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | -48.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 2481     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 64881    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 3720     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | -41.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 2392     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 65913    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0444   |\n",
      "|    n_updates        | 3978     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | -47.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 2305     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 67024    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 4255     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | -42.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 2234     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 68052    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 4512     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | -43.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 2165     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 69102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 4775     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | -47.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 2098     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 70224    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 5055     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | -43.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 2041     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 71306    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.477    |\n",
      "|    n_updates        | 5326     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.4     |\n",
      "|    ep_rew_mean      | -50.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 1985     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 72448    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 5611     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | -46.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 1934     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 73565    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.326    |\n",
      "|    n_updates        | 5891     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | -41.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 1892     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 74605    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0906   |\n",
      "|    n_updates        | 6151     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | -44.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 1851     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 75682    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 6420     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | -39.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 1814     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 76711    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 6677     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | -50.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 1776     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 77877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0691   |\n",
      "|    n_updates        | 6969     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | -42.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 1744     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 78928    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 7231     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | -47.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 1711     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 80054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 7513     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | -44      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 1681     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 81138    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.512    |\n",
      "|    n_updates        | 7784     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | -47.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 1653     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 82257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0848   |\n",
      "|    n_updates        | 8064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | -40.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 1628     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 83289    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 8322     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | -42.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 1603     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 84348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.077    |\n",
      "|    n_updates        | 8586     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | -44.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 1580     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 85412    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 8852     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | -46.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 1557     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 86526    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 9131     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | -45.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 1536     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 87612    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.649    |\n",
      "|    n_updates        | 9402     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | -49.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 1515     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 88779    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 9694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | -47.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 1496     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 89888    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.426    |\n",
      "|    n_updates        | 9971     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | -50.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 1477     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 91054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 10263    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | -42.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 1460     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 92108    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 10526    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | -48.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 1443     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 93260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 10814    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | -46.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 1427     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 94380    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.548    |\n",
      "|    n_updates        | 11094    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | -44.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 1412     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 95453    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0702   |\n",
      "|    n_updates        | 11363    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | -40.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3900     |\n",
      "|    fps              | 1399     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 96472    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0467   |\n",
      "|    n_updates        | 11617    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | -41.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4000     |\n",
      "|    fps              | 1386     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 97526    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 11881    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | -42      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4100     |\n",
      "|    fps              | 1372     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 98580    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 12144    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | -41.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4200     |\n",
      "|    fps              | 1359     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 99620    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.375    |\n",
      "|    n_updates        | 12404    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common import logger\n",
    "# Train the agent by the stable_baselines3\n",
    "import os\n",
    "models_dir = './models/PPO'\n",
    "logdir = './logs'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "env = MyCar()\n",
    "agent = DQN('MlpPolicy', env, verbose=1,tensorboard_log=logdir)\n",
    "agent.learn(total_timesteps=100000, log_interval=100,tb_log_name='DQN')\n",
    "agent.save(\"DQN_MyCar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "[6. 5.]\n",
      "[5. 5.]\n",
      "[5. 4.]\n",
      "[4. 4.]\n",
      "[4. 3.]\n",
      "[3. 3.]\n",
      "[2. 3.]\n",
      "[2. 2.]\n",
      "[2. 3.]\n",
      "[2. 2.]\n",
      "[2. 1.]\n",
      "[1. 1.]\n",
      "[1. 0.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "env = MyCar()\n",
    "obs = env.reset()\n",
    "agent = DQN.load('deepq_cartpole.zip',env=env)\n",
    "terminated = False\n",
    "while not terminated:\n",
    "    action,_state = agent.predict(obs)\n",
    "    obs,rew,terminated,truncated,info = env.step(action)\n",
    "    print(env.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
