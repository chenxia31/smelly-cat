{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "本文研究的依旧是[《基于论文摘要的文本分类与关键词抽取挑战赛](https://challenge.xfyun.cn/topic/info?type=abstract-of-the-paper&option=tjjg&ch=ZuoaKcY)任务一，是文本分类任务，尝试使用Bert进行微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0x01 完整流程\n",
    "完整的深度学习工作过程包括：\n",
    "1. 数据预处理\n",
    "2. Dataset和Dataloader撰写\n",
    "3. 确定Model框架\n",
    "4. optimization\n",
    "5. loss function\n",
    "6. 超参数设置，epoch、lr等\n",
    "7. train\n",
    "8. evaluation\n",
    "在本文中我们常使用Bert作为主要的model框架，在训练过程中使用pre-train+finetuning的范式进行参数优化\n",
    "* 预训练+微调范式，指先在海量文本数据上进行预训练，再针对特定的下游任务进行微调。预训练一般基于语言模型，即给定上一个词，预测下一个词。语言模型可以在所有文本数据上建模，无需人工标注，因此很容易在海量数据上进行训练。通过在海量数据上进行预训练，模型可以学习到深层的自然语言逻辑。再通过在指定的下游任务上进行微调，即针对部分人工标注的任务数据进行特定训练，如文本分类、文本生成等，来训练模型执行下游任务的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "# 文本的最大长度\n",
    "text_max_length = 128\n",
    "# 总训练的epochs数，我只是随便定义了个数\n",
    "epochs = 100\n",
    "# 学习率\n",
    "lr = 3e-5\n",
    "# 取多少训练集的数据作为验证集\n",
    "validation_ratio = 0.2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 每多少步，打印一次loss\n",
    "log_per_step = 50\n",
    "\n",
    "# 数据集所在位置\n",
    "dataset_dir = Path(\"../data\")\n",
    "os.makedirs(dataset_dir) if not os.path.exists(dataset_dir) else ''\n",
    "\n",
    "# 模型存储路径\n",
    "model_dir = Path(\"../output//bert_checkpoints\")\n",
    "# 如果模型目录不存在，则创建一个\n",
    "os.makedirs(model_dir) if not os.path.exists(model_dir) else ''\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train_data = pd.read_csv('../data/train.csv')\n",
    "pd_train_data['title'] = pd_train_data['title'].fillna('')\n",
    "pd_train_data['abstract'] = pd_train_data['abstract'].fillna('')\n",
    "\n",
    "test_data = pd.read_csv('../data/testB.csv')\n",
    "test_data['title'] = test_data['title'].fillna('')\n",
    "test_data['abstract'] = test_data['abstract'].fillna('')\n",
    "pd_train_data['text'] = pd_train_data['title'].fillna('') + ' ' +  pd_train_data['author'].fillna('') + ' ' + pd_train_data['abstract'].fillna('')+ ' ' + pd_train_data['Keywords'].fillna('')\n",
    "test_data['text'] = test_data['title'].fillna('') + ' ' +  test_data['author'].fillna('') + ' ' + test_data['abstract'].fillna('')+ ' ' + pd_train_data['Keywords'].fillna('')\n",
    "test_data['Keywords'] = test_data['title'].fillna('')\n",
    "\n",
    "# 从训练集中随机采样测试集\n",
    "validation_data = pd_train_data.sample(frac=validation_ratio)\n",
    "train_data = pd_train_data[~pd_train_data.index.isin(validation_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Dataset\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mode='train'):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        # 拿到对应的数据\n",
    "        if mode == 'train':\n",
    "            self.dataset = train_data\n",
    "        elif mode == 'validation':\n",
    "            self.dataset = validation_data\n",
    "        elif mode == 'test':\n",
    "            # 如果是测试模式，则返回内容和uuid。拿uuid做target主要是方便后面写入结果。\n",
    "            self.dataset = test_data\n",
    "        else:\n",
    "            raise Exception(\"Unknown mode {}\".format(mode))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 取第index条\n",
    "        data = self.dataset.iloc[index]\n",
    "        # 取其内容\n",
    "        text = data['text']\n",
    "        # 根据状态返回内容\n",
    "        if self.mode == 'test':\n",
    "            # 如果是test，将uuid做为target\n",
    "            label = data['uuid']\n",
    "        else:\n",
    "            label = data['label']\n",
    "        # 返回内容和label\n",
    "        return text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "train_dataset = MyDataset('train')\n",
    "validation_dataset = MyDataset('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608cb782f99d43689c490ae910de962d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5724dd5d2dc747ec8f9db5dac2479611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e93d52bd69e4805af56341baaae954a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3475323d6d264dc29cfbf66430cbed1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#获取Bert预训练模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#接着构造我们的Dataloader。\n",
    "#我们需要定义一下collate_fn，在其中完成对句子进行编码、填充、组装batch等动作：\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    将一个batch的文本句子转成tensor，并组成batch。\n",
    "    :param batch: 一个batch的句子，例如: [('推文', target), ('推文', target), ...]\n",
    "    :return: 处理后的结果，例如：\n",
    "             src: {'input_ids': tensor([[ 101, ..., 102, 0, 0, ...], ...]), 'attention_mask': tensor([[1, ..., 1, 0, ...], ...])}\n",
    "             target：[1, 1, 0, ...]\n",
    "    \"\"\"\n",
    "    text, label = zip(*batch)\n",
    "    text, label = list(text), list(label)\n",
    "\n",
    "    # src是要送给bert的，所以不需要特殊处理，直接用tokenizer的结果即可\n",
    "    # padding='max_length' 不够长度的进行填充\n",
    "    # truncation=True 长度过长的进行裁剪\n",
    "    src = tokenizer(text, padding='max_length', max_length=text_max_length, return_tensors='pt', truncation=True)\n",
    "\n",
    "    return src, torch.LongTensor(label)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'input_ids': tensor([[  101,  2217, 21833,  ...,  1997,  1011,   102],\n",
      "        [  101, 11131,  1996,  ...,  1037,  2062,   102],\n",
      "        [  101,  2784, 12046,  ..., 10616,  1996,   102],\n",
      "        ...,\n",
      "        [  101,  3444, 10077,  ...,  2389,  2838,   102],\n",
      "        [  101, 11131,  6123,  ...,  2591,  2865,   102],\n",
      "        [  101, 19132, 12046,  ..., 26633,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "targets: tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(iter(train_loader))\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"targets:\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6d960bba504dee98c53e3803e62e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#定义预测模型，该模型由bert模型加上最后的预测层组成\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 加载bert模型\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased', mirror='tuna')\n",
    "\n",
    "        # 最后的预测层\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        :param src: 分词后的推文数据\n",
    "        \"\"\"\n",
    "\n",
    "        # 将src直接序列解包传入bert，因为bert和tokenizer是一套的，所以可以这么做。\n",
    "        # 得到encoder的输出，用最前面[CLS]的输出作为最终线性层的输入\n",
    "        outputs = self.bert(**src).last_hidden_state[:, 0, :]\n",
    "\n",
    "        # 使用线性层来做最终的预测\n",
    "        return self.predictor(outputs)\n",
    "model = MyModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义出损失函数和优化器。这里使用Binary Cross Entropy：\n",
    "criteria = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# 由于inputs是字典类型的，定义一个辅助函数帮助to(device)\n",
    "def to_device(dict_tensors):\n",
    "    result_tensors = {}\n",
    "    for key, value in dict_tensors.items():\n",
    "        result_tensors[key] = value.to(device)\n",
    "    return result_tensors\n",
    "\n",
    "#定义一个验证方法，获取到验证集的精准率和loss\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_correct = 0\n",
    "    for inputs, targets in validation_loader:\n",
    "        inputs, targets = to_device(inputs), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criteria(outputs.view(-1), targets.float())\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        correct_num = (((outputs >= 0.5).float() * 1).flatten() == targets).sum()\n",
    "        total_correct += correct_num\n",
    "\n",
    "    return total_correct / len(validation_dataset), total_loss / len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Step: 49/300, total loss:15.6531\n",
      "Epoch 1/100, Step: 99/300, total loss:7.3114\n",
      "Epoch 1/100, Step: 149/300, total loss:6.7847\n",
      "Epoch 1/100, Step: 199/300, total loss:5.5224\n",
      "Epoch 1/100, Step: 249/300, total loss:6.5372\n",
      "Epoch 1/100, Step: 299/300, total loss:5.6269\n",
      "Epoch 1, accuracy: 0.9775, validation loss: 0.0043\n",
      "Epoch 2/100, Step: 49/300, total loss:3.3247\n",
      "Epoch 2/100, Step: 99/300, total loss:4.5499\n",
      "Epoch 2/100, Step: 149/300, total loss:4.9799\n",
      "Epoch 2/100, Step: 199/300, total loss:3.4573\n",
      "Epoch 2/100, Step: 249/300, total loss:2.3852\n",
      "Epoch 2/100, Step: 299/300, total loss:5.0425\n",
      "Epoch 2, accuracy: 0.9700, validation loss: 0.0044\n",
      "Epoch 3/100, Step: 49/300, total loss:2.9828\n",
      "Epoch 3/100, Step: 99/300, total loss:2.0558\n",
      "Epoch 3/100, Step: 149/300, total loss:3.1461\n",
      "Epoch 3/100, Step: 199/300, total loss:3.8905\n",
      "Epoch 3/100, Step: 249/300, total loss:2.2181\n",
      "Epoch 3/100, Step: 299/300, total loss:2.3955\n",
      "Epoch 3, accuracy: 0.9733, validation loss: 0.0046\n",
      "Epoch 4/100, Step: 49/300, total loss:2.1008\n",
      "Epoch 4/100, Step: 99/300, total loss:1.1108\n",
      "Epoch 4/100, Step: 149/300, total loss:2.0474\n",
      "Epoch 4/100, Step: 199/300, total loss:3.1949\n",
      "Epoch 4/100, Step: 249/300, total loss:2.8249\n",
      "Epoch 4/100, Step: 299/300, total loss:1.9376\n",
      "Epoch 4, accuracy: 0.9633, validation loss: 0.0058\n",
      "Epoch 5/100, Step: 49/300, total loss:1.3280\n",
      "Epoch 5/100, Step: 99/300, total loss:2.4661\n",
      "Epoch 5/100, Step: 149/300, total loss:1.2560\n",
      "Epoch 5/100, Step: 199/300, total loss:1.5075\n",
      "Epoch 5/100, Step: 249/300, total loss:1.1041\n",
      "Epoch 5/100, Step: 299/300, total loss:0.9700\n",
      "Epoch 5, accuracy: 0.9725, validation loss: 0.0057\n",
      "Epoch 6/100, Step: 49/300, total loss:2.3236\n",
      "Epoch 6/100, Step: 99/300, total loss:1.4776\n",
      "Epoch 6/100, Step: 149/300, total loss:1.4090\n",
      "Epoch 6/100, Step: 199/300, total loss:1.3598\n",
      "Epoch 6/100, Step: 249/300, total loss:0.8684\n",
      "Epoch 6/100, Step: 299/300, total loss:3.2083\n",
      "Epoch 6, accuracy: 0.9708, validation loss: 0.0058\n",
      "Epoch 7/100, Step: 49/300, total loss:1.2689\n",
      "Epoch 7/100, Step: 99/300, total loss:1.7892\n",
      "Epoch 7/100, Step: 149/300, total loss:0.6506\n",
      "Epoch 7/100, Step: 199/300, total loss:0.1637\n",
      "Epoch 7/100, Step: 249/300, total loss:0.8090\n",
      "Epoch 7/100, Step: 299/300, total loss:0.4767\n",
      "Epoch 7, accuracy: 0.9733, validation loss: 0.0070\n",
      "Epoch 8/100, Step: 49/300, total loss:0.1703\n",
      "Epoch 8/100, Step: 99/300, total loss:0.2374\n",
      "Epoch 8/100, Step: 149/300, total loss:0.6825\n",
      "Epoch 8/100, Step: 199/300, total loss:0.3465\n",
      "Epoch 8/100, Step: 249/300, total loss:0.3493\n",
      "Epoch 8/100, Step: 299/300, total loss:0.3267\n",
      "Epoch 8, accuracy: 0.9733, validation loss: 0.0085\n",
      "Epoch 9/100, Step: 49/300, total loss:0.2811\n",
      "Epoch 9/100, Step: 99/300, total loss:0.2782\n",
      "Epoch 9/100, Step: 149/300, total loss:0.9273\n",
      "Epoch 9/100, Step: 199/300, total loss:0.6116\n",
      "Epoch 9/100, Step: 249/300, total loss:0.3393\n",
      "Epoch 9/100, Step: 299/300, total loss:0.5216\n",
      "Epoch 9, accuracy: 0.9692, validation loss: 0.0076\n",
      "Epoch 10/100, Step: 49/300, total loss:0.0746\n",
      "Epoch 10/100, Step: 99/300, total loss:0.0260\n",
      "Epoch 10/100, Step: 149/300, total loss:0.8774\n",
      "Epoch 10/100, Step: 199/300, total loss:0.9549\n",
      "Epoch 10/100, Step: 249/300, total loss:0.7367\n",
      "Epoch 10/100, Step: 299/300, total loss:0.4596\n",
      "Epoch 10, accuracy: 0.9775, validation loss: 0.0070\n",
      "Epoch 11/100, Step: 49/300, total loss:0.7258\n",
      "Epoch 11/100, Step: 99/300, total loss:0.6408\n",
      "Epoch 11/100, Step: 149/300, total loss:0.8267\n",
      "Epoch 11/100, Step: 199/300, total loss:0.1608\n",
      "Epoch 11/100, Step: 249/300, total loss:0.6685\n",
      "Epoch 11/100, Step: 299/300, total loss:0.2064\n",
      "Epoch 11, accuracy: 0.9800, validation loss: 0.0072\n",
      "Epoch 12/100, Step: 49/300, total loss:0.2670\n",
      "Epoch 12/100, Step: 99/300, total loss:0.1514\n",
      "Epoch 12/100, Step: 149/300, total loss:0.0348\n",
      "Epoch 12/100, Step: 199/300, total loss:0.0242\n",
      "Epoch 12/100, Step: 249/300, total loss:1.9069\n",
      "Epoch 12/100, Step: 299/300, total loss:0.1442\n",
      "Epoch 12, accuracy: 0.9792, validation loss: 0.0084\n",
      "Epoch 13/100, Step: 49/300, total loss:0.0207\n",
      "Epoch 13/100, Step: 99/300, total loss:0.0275\n",
      "Epoch 13/100, Step: 149/300, total loss:0.0420\n",
      "Epoch 13/100, Step: 199/300, total loss:0.0332\n",
      "Epoch 13/100, Step: 249/300, total loss:0.2014\n",
      "Epoch 13/100, Step: 299/300, total loss:0.4325\n",
      "Epoch 13, accuracy: 0.9758, validation loss: 0.0088\n",
      "Epoch 14/100, Step: 49/300, total loss:0.0156\n",
      "Epoch 14/100, Step: 99/300, total loss:0.1316\n",
      "Epoch 14/100, Step: 149/300, total loss:1.8511\n",
      "Epoch 14/100, Step: 199/300, total loss:0.4720\n",
      "Epoch 14/100, Step: 249/300, total loss:0.0299\n",
      "Epoch 14/100, Step: 299/300, total loss:0.0381\n",
      "Epoch 14, accuracy: 0.9808, validation loss: 0.0070\n",
      "Epoch 15/100, Step: 49/300, total loss:0.0141\n",
      "Epoch 15/100, Step: 99/300, total loss:1.1196\n",
      "Epoch 15/100, Step: 149/300, total loss:0.3874\n",
      "Epoch 15/100, Step: 199/300, total loss:0.1547\n",
      "Epoch 15/100, Step: 249/300, total loss:0.0379\n",
      "Epoch 15/100, Step: 299/300, total loss:0.0228\n",
      "Epoch 15, accuracy: 0.9825, validation loss: 0.0071\n",
      "Epoch 16/100, Step: 49/300, total loss:0.5117\n",
      "Epoch 16/100, Step: 99/300, total loss:0.0216\n",
      "Epoch 16/100, Step: 149/300, total loss:0.0529\n",
      "Epoch 16/100, Step: 199/300, total loss:0.5768\n",
      "Epoch 16/100, Step: 249/300, total loss:0.5813\n",
      "Epoch 16/100, Step: 299/300, total loss:0.0406\n",
      "Epoch 16, accuracy: 0.9758, validation loss: 0.0069\n",
      "Epoch 17/100, Step: 49/300, total loss:0.4421\n",
      "Epoch 17/100, Step: 99/300, total loss:0.3893\n",
      "Epoch 17/100, Step: 149/300, total loss:0.0914\n",
      "Epoch 17/100, Step: 199/300, total loss:0.0187\n",
      "Epoch 17/100, Step: 249/300, total loss:0.6829\n",
      "Epoch 17/100, Step: 299/300, total loss:0.5471\n",
      "Epoch 17, accuracy: 0.9800, validation loss: 0.0065\n",
      "Epoch 18/100, Step: 49/300, total loss:0.0994\n",
      "Epoch 18/100, Step: 99/300, total loss:0.4810\n",
      "Epoch 18/100, Step: 149/300, total loss:0.3109\n",
      "Epoch 18/100, Step: 199/300, total loss:0.2267\n",
      "Epoch 18/100, Step: 249/300, total loss:0.3000\n",
      "Epoch 18/100, Step: 299/300, total loss:2.4657\n",
      "Epoch 18, accuracy: 0.9775, validation loss: 0.0069\n",
      "Epoch 19/100, Step: 49/300, total loss:0.4669\n",
      "Epoch 19/100, Step: 99/300, total loss:0.1503\n",
      "Epoch 19/100, Step: 149/300, total loss:0.0284\n",
      "Epoch 19/100, Step: 199/300, total loss:0.0215\n",
      "Epoch 19/100, Step: 249/300, total loss:0.0601\n",
      "Epoch 19/100, Step: 299/300, total loss:0.0221\n",
      "Epoch 19, accuracy: 0.9858, validation loss: 0.0070\n",
      "Epoch 20/100, Step: 49/300, total loss:0.0431\n",
      "Epoch 20/100, Step: 99/300, total loss:0.2542\n",
      "Epoch 20/100, Step: 149/300, total loss:0.6912\n",
      "Epoch 20/100, Step: 199/300, total loss:0.1470\n",
      "Epoch 20/100, Step: 249/300, total loss:0.0653\n",
      "Epoch 20/100, Step: 299/300, total loss:0.0393\n",
      "Epoch 20, accuracy: 0.9808, validation loss: 0.0070\n",
      "Epoch 21/100, Step: 49/300, total loss:0.0468\n",
      "Epoch 21/100, Step: 99/300, total loss:0.0171\n",
      "Epoch 21/100, Step: 149/300, total loss:0.0114\n",
      "Epoch 21/100, Step: 199/300, total loss:0.0060\n",
      "Epoch 21/100, Step: 249/300, total loss:0.0049\n",
      "Epoch 21/100, Step: 299/300, total loss:0.0049\n",
      "Epoch 21, accuracy: 0.9767, validation loss: 0.0095\n",
      "Epoch 22/100, Step: 49/300, total loss:0.1095\n",
      "Epoch 22/100, Step: 99/300, total loss:0.5526\n",
      "Epoch 22/100, Step: 149/300, total loss:0.0612\n",
      "Epoch 22/100, Step: 199/300, total loss:0.1260\n",
      "Epoch 22/100, Step: 249/300, total loss:0.8813\n",
      "Epoch 22/100, Step: 299/300, total loss:0.4211\n",
      "Epoch 22, accuracy: 0.9750, validation loss: 0.0076\n",
      "Epoch 23/100, Step: 49/300, total loss:0.7089\n",
      "Epoch 23/100, Step: 99/300, total loss:0.6731\n",
      "Epoch 23/100, Step: 149/300, total loss:0.1547\n",
      "Epoch 23/100, Step: 199/300, total loss:0.0309\n",
      "Epoch 23/100, Step: 249/300, total loss:0.0266\n",
      "Epoch 23/100, Step: 299/300, total loss:0.4777\n",
      "Epoch 23, accuracy: 0.9717, validation loss: 0.0093\n",
      "Epoch 24/100, Step: 49/300, total loss:0.4645\n",
      "Epoch 24/100, Step: 99/300, total loss:0.1729\n",
      "Epoch 24/100, Step: 149/300, total loss:0.0691\n",
      "Epoch 24/100, Step: 199/300, total loss:0.0090\n",
      "Epoch 24/100, Step: 249/300, total loss:0.0139\n",
      "Epoch 24/100, Step: 299/300, total loss:0.0043\n",
      "Epoch 24, accuracy: 0.9825, validation loss: 0.0068\n",
      "Epoch 25/100, Step: 49/300, total loss:0.0104\n",
      "Epoch 25/100, Step: 99/300, total loss:0.0044\n",
      "Epoch 25/100, Step: 149/300, total loss:0.0039\n",
      "Epoch 25/100, Step: 199/300, total loss:0.0038\n",
      "Epoch 25/100, Step: 249/300, total loss:0.0035\n",
      "Epoch 25/100, Step: 299/300, total loss:0.0031\n",
      "Epoch 25, accuracy: 0.9817, validation loss: 0.0073\n",
      "Epoch 26/100, Step: 49/300, total loss:0.0031\n",
      "Epoch 26/100, Step: 99/300, total loss:0.0029\n",
      "Epoch 26/100, Step: 149/300, total loss:0.0028\n",
      "Epoch 26/100, Step: 199/300, total loss:0.0026\n",
      "Epoch 26/100, Step: 249/300, total loss:0.0048\n",
      "Epoch 26/100, Step: 299/300, total loss:0.0030\n",
      "Epoch 26, accuracy: 0.9775, validation loss: 0.0082\n",
      "Epoch 27/100, Step: 49/300, total loss:0.0023\n",
      "Epoch 27/100, Step: 99/300, total loss:0.0024\n",
      "Epoch 27/100, Step: 149/300, total loss:0.0024\n",
      "Epoch 27/100, Step: 199/300, total loss:0.0020\n",
      "Epoch 27/100, Step: 249/300, total loss:0.0021\n",
      "Epoch 27/100, Step: 299/300, total loss:2.5634\n",
      "Epoch 27, accuracy: 0.9692, validation loss: 0.0132\n",
      "Epoch 28/100, Step: 49/300, total loss:1.0115\n",
      "Epoch 28/100, Step: 99/300, total loss:0.0447\n",
      "Epoch 28/100, Step: 149/300, total loss:0.0173\n",
      "Epoch 28/100, Step: 199/300, total loss:0.0109\n",
      "Epoch 28/100, Step: 249/300, total loss:0.2660\n",
      "Epoch 28/100, Step: 299/300, total loss:0.0102\n",
      "Epoch 28, accuracy: 0.9808, validation loss: 0.0084\n",
      "Epoch 29/100, Step: 49/300, total loss:0.0100\n",
      "Epoch 29/100, Step: 99/300, total loss:0.0069\n",
      "Epoch 29/100, Step: 149/300, total loss:0.0053\n",
      "Epoch 29/100, Step: 199/300, total loss:0.9231\n",
      "Epoch 29/100, Step: 249/300, total loss:0.4045\n",
      "Epoch 29/100, Step: 299/300, total loss:0.1954\n",
      "Epoch 29, accuracy: 0.9817, validation loss: 0.0070\n",
      "Epoch 30/100, Step: 49/300, total loss:0.1547\n",
      "Epoch 30/100, Step: 99/300, total loss:0.0175\n",
      "Epoch 30/100, Step: 149/300, total loss:0.0052\n",
      "Epoch 30/100, Step: 199/300, total loss:0.0062\n",
      "Epoch 30/100, Step: 249/300, total loss:0.0043\n",
      "Epoch 30/100, Step: 299/300, total loss:0.0044\n",
      "Epoch 30, accuracy: 0.9800, validation loss: 0.0090\n",
      "Epoch 31/100, Step: 49/300, total loss:0.0056\n",
      "Epoch 31/100, Step: 99/300, total loss:0.0035\n",
      "Epoch 31/100, Step: 149/300, total loss:0.0033\n",
      "Epoch 31/100, Step: 199/300, total loss:0.0032\n",
      "Epoch 31/100, Step: 249/300, total loss:0.0031\n",
      "Epoch 31/100, Step: 299/300, total loss:0.0027\n",
      "Epoch 31, accuracy: 0.9800, validation loss: 0.0096\n",
      "Epoch 32/100, Step: 49/300, total loss:0.0027\n",
      "Epoch 32/100, Step: 99/300, total loss:0.0032\n",
      "Epoch 32/100, Step: 149/300, total loss:0.0026\n",
      "Epoch 32/100, Step: 199/300, total loss:0.0024\n",
      "Epoch 32/100, Step: 249/300, total loss:0.0022\n",
      "Epoch 32/100, Step: 299/300, total loss:0.0022\n",
      "Epoch 32, accuracy: 0.9800, validation loss: 0.0098\n",
      "Epoch 33/100, Step: 49/300, total loss:0.0021\n",
      "Epoch 33/100, Step: 99/300, total loss:0.0020\n",
      "Epoch 33/100, Step: 149/300, total loss:0.0021\n",
      "Epoch 33/100, Step: 199/300, total loss:0.0021\n",
      "Epoch 33/100, Step: 249/300, total loss:0.0018\n",
      "Epoch 33/100, Step: 299/300, total loss:0.0018\n",
      "Epoch 33, accuracy: 0.9800, validation loss: 0.0101\n",
      "Epoch 34/100, Step: 49/300, total loss:0.0017\n",
      "Epoch 34/100, Step: 99/300, total loss:0.0017\n",
      "Epoch 34/100, Step: 149/300, total loss:0.0017\n",
      "Epoch 34/100, Step: 199/300, total loss:0.0017\n",
      "Epoch 34/100, Step: 249/300, total loss:0.0015\n",
      "Epoch 34/100, Step: 299/300, total loss:0.0016\n",
      "Epoch 34, accuracy: 0.9800, validation loss: 0.0104\n",
      "Epoch 35/100, Step: 49/300, total loss:0.0015\n",
      "Epoch 35/100, Step: 99/300, total loss:0.0014\n",
      "Epoch 35/100, Step: 149/300, total loss:0.0014\n",
      "Epoch 35/100, Step: 199/300, total loss:0.0013\n",
      "Epoch 35/100, Step: 249/300, total loss:0.0013\n",
      "Epoch 35/100, Step: 299/300, total loss:0.0012\n",
      "Epoch 35, accuracy: 0.9800, validation loss: 0.0106\n",
      "Epoch 36/100, Step: 49/300, total loss:0.0012\n",
      "Epoch 36/100, Step: 99/300, total loss:0.0012\n",
      "Epoch 36/100, Step: 149/300, total loss:0.0012\n",
      "Epoch 36/100, Step: 199/300, total loss:0.0011\n",
      "Epoch 36/100, Step: 249/300, total loss:0.0011\n",
      "Epoch 36/100, Step: 299/300, total loss:0.0011\n",
      "Epoch 36, accuracy: 0.9800, validation loss: 0.0108\n",
      "Epoch 37/100, Step: 49/300, total loss:0.0010\n",
      "Epoch 37/100, Step: 99/300, total loss:0.0010\n",
      "Epoch 37/100, Step: 149/300, total loss:0.0010\n",
      "Epoch 37/100, Step: 199/300, total loss:0.0010\n",
      "Epoch 37/100, Step: 249/300, total loss:0.0009\n",
      "Epoch 37/100, Step: 299/300, total loss:0.0009\n",
      "Epoch 37, accuracy: 0.9800, validation loss: 0.0110\n",
      "Epoch 38/100, Step: 49/300, total loss:0.0009\n",
      "Epoch 38/100, Step: 99/300, total loss:0.0009\n",
      "Epoch 38/100, Step: 149/300, total loss:0.0012\n",
      "Epoch 38/100, Step: 199/300, total loss:0.0008\n",
      "Epoch 38/100, Step: 249/300, total loss:0.0008\n",
      "Epoch 38/100, Step: 299/300, total loss:0.0007\n",
      "Epoch 38, accuracy: 0.9800, validation loss: 0.0113\n",
      "Epoch 39/100, Step: 49/300, total loss:0.0007\n",
      "Epoch 39/100, Step: 99/300, total loss:0.0007\n",
      "Epoch 39/100, Step: 149/300, total loss:0.0008\n",
      "Epoch 39/100, Step: 199/300, total loss:0.0007\n",
      "Epoch 39/100, Step: 249/300, total loss:0.0006\n",
      "Epoch 39/100, Step: 299/300, total loss:0.0006\n",
      "Epoch 39, accuracy: 0.9800, validation loss: 0.0115\n",
      "Epoch 40/100, Step: 49/300, total loss:0.0006\n",
      "Epoch 40/100, Step: 99/300, total loss:0.0006\n",
      "Epoch 40/100, Step: 149/300, total loss:0.0006\n",
      "Epoch 40/100, Step: 199/300, total loss:0.0006\n",
      "Epoch 40/100, Step: 249/300, total loss:0.0006\n",
      "Epoch 40/100, Step: 299/300, total loss:0.0006\n",
      "Epoch 40, accuracy: 0.9800, validation loss: 0.0117\n",
      "Epoch 41/100, Step: 49/300, total loss:0.0005\n",
      "Epoch 41/100, Step: 99/300, total loss:0.0005\n",
      "Epoch 41/100, Step: 149/300, total loss:0.0005\n",
      "Epoch 41/100, Step: 199/300, total loss:0.0005\n",
      "Epoch 41/100, Step: 249/300, total loss:0.0005\n",
      "Epoch 41/100, Step: 299/300, total loss:0.0005\n",
      "Epoch 41, accuracy: 0.9800, validation loss: 0.0119\n",
      "Epoch 42/100, Step: 49/300, total loss:0.0004\n",
      "Epoch 42/100, Step: 99/300, total loss:0.0004\n",
      "Epoch 42/100, Step: 149/300, total loss:0.0004\n",
      "Epoch 42/100, Step: 199/300, total loss:0.0004\n",
      "Epoch 42/100, Step: 249/300, total loss:0.0004\n",
      "Epoch 42/100, Step: 299/300, total loss:0.0004\n",
      "Epoch 42, accuracy: 0.9800, validation loss: 0.0121\n",
      "Epoch 43/100, Step: 49/300, total loss:0.0004\n",
      "Epoch 43/100, Step: 99/300, total loss:0.0004\n",
      "Epoch 43/100, Step: 149/300, total loss:0.0004\n",
      "Epoch 43/100, Step: 199/300, total loss:0.0003\n",
      "Epoch 43/100, Step: 249/300, total loss:0.0004\n",
      "Epoch 43/100, Step: 299/300, total loss:0.0003\n",
      "Epoch 43, accuracy: 0.9800, validation loss: 0.0123\n",
      "Epoch 44/100, Step: 49/300, total loss:0.0003\n",
      "Epoch 44/100, Step: 99/300, total loss:0.0003\n",
      "Epoch 44/100, Step: 149/300, total loss:0.0003\n",
      "Epoch 44/100, Step: 199/300, total loss:0.0003\n",
      "Epoch 44/100, Step: 249/300, total loss:0.0003\n",
      "Epoch 44/100, Step: 299/300, total loss:0.0003\n",
      "Epoch 44, accuracy: 0.9800, validation loss: 0.0124\n",
      "Epoch 45/100, Step: 49/300, total loss:0.0003\n",
      "Epoch 45/100, Step: 99/300, total loss:0.0003\n",
      "Epoch 45/100, Step: 149/300, total loss:0.0003\n",
      "Epoch 45/100, Step: 199/300, total loss:0.0003\n",
      "Epoch 45/100, Step: 249/300, total loss:0.0002\n",
      "Epoch 45/100, Step: 299/300, total loss:0.0002\n",
      "Epoch 45, accuracy: 0.9800, validation loss: 0.0126\n",
      "Epoch 46/100, Step: 49/300, total loss:0.0002\n",
      "Epoch 46/100, Step: 99/300, total loss:0.0002\n",
      "Epoch 46/100, Step: 149/300, total loss:0.0002\n",
      "Epoch 46/100, Step: 199/300, total loss:0.0002\n",
      "Epoch 46/100, Step: 249/300, total loss:0.0002\n",
      "Epoch 46/100, Step: 299/300, total loss:0.0002\n",
      "Epoch 46, accuracy: 0.9800, validation loss: 0.0128\n",
      "Epoch 47/100, Step: 49/300, total loss:0.0002\n",
      "Epoch 47/100, Step: 99/300, total loss:0.0002\n",
      "Epoch 47/100, Step: 149/300, total loss:0.0002\n",
      "Epoch 47/100, Step: 199/300, total loss:0.0002\n",
      "Epoch 47/100, Step: 249/300, total loss:0.0002\n",
      "Epoch 47/100, Step: 299/300, total loss:0.0002\n",
      "Epoch 47, accuracy: 0.9800, validation loss: 0.0130\n",
      "Epoch 48/100, Step: 49/300, total loss:0.0002\n",
      "Epoch 48/100, Step: 99/300, total loss:0.0002\n",
      "Epoch 48/100, Step: 149/300, total loss:0.0002\n",
      "Epoch 48/100, Step: 199/300, total loss:0.0002\n",
      "Epoch 48/100, Step: 249/300, total loss:0.0002\n",
      "Epoch 48/100, Step: 299/300, total loss:0.0001\n",
      "Epoch 48, accuracy: 0.9800, validation loss: 0.0133\n",
      "Epoch 49/100, Step: 49/300, total loss:0.0001\n",
      "Epoch 49/100, Step: 99/300, total loss:0.0001\n",
      "Epoch 49/100, Step: 149/300, total loss:1.5287\n",
      "Epoch 49/100, Step: 199/300, total loss:3.2634\n",
      "Epoch 49/100, Step: 249/300, total loss:5.4949\n",
      "Epoch 49/100, Step: 299/300, total loss:3.1370\n",
      "Epoch 49, accuracy: 0.9708, validation loss: 0.0081\n",
      "Epoch 50/100, Step: 49/300, total loss:1.5351\n",
      "Epoch 50/100, Step: 99/300, total loss:1.2598\n",
      "Epoch 50/100, Step: 149/300, total loss:0.6211\n",
      "Epoch 50/100, Step: 199/300, total loss:0.3406\n",
      "Epoch 50/100, Step: 249/300, total loss:0.7154\n",
      "Epoch 50/100, Step: 299/300, total loss:0.8614\n",
      "Epoch 50, accuracy: 0.9775, validation loss: 0.0063\n",
      "Epoch 51/100, Step: 49/300, total loss:0.0965\n",
      "Epoch 51/100, Step: 99/300, total loss:0.0324\n",
      "Epoch 51/100, Step: 149/300, total loss:0.0237\n",
      "Epoch 51/100, Step: 199/300, total loss:0.0149\n",
      "Epoch 51/100, Step: 249/300, total loss:1.0205\n",
      "Epoch 51/100, Step: 299/300, total loss:0.6719\n",
      "Epoch 51, accuracy: 0.9775, validation loss: 0.0065\n",
      "Epoch 52/100, Step: 49/300, total loss:0.5751\n",
      "Epoch 52/100, Step: 99/300, total loss:0.0515\n",
      "Epoch 52/100, Step: 149/300, total loss:0.0242\n",
      "Epoch 52/100, Step: 199/300, total loss:0.3753\n",
      "Epoch 52/100, Step: 249/300, total loss:0.7021\n",
      "Epoch 52/100, Step: 299/300, total loss:0.0812\n",
      "Epoch 52, accuracy: 0.9783, validation loss: 0.0073\n",
      "Epoch 53/100, Step: 49/300, total loss:0.0120\n",
      "Epoch 53/100, Step: 99/300, total loss:0.0849\n",
      "Epoch 53/100, Step: 149/300, total loss:0.0135\n",
      "Epoch 53/100, Step: 199/300, total loss:0.0411\n",
      "Epoch 53/100, Step: 249/300, total loss:0.0064\n",
      "Epoch 53/100, Step: 299/300, total loss:0.0135\n",
      "Epoch 53, accuracy: 0.9725, validation loss: 0.0122\n",
      "Epoch 54/100, Step: 49/300, total loss:0.0280\n",
      "Epoch 54/100, Step: 99/300, total loss:0.0050\n",
      "Epoch 54/100, Step: 149/300, total loss:0.0044\n",
      "Epoch 54/100, Step: 199/300, total loss:0.0040\n",
      "Epoch 54/100, Step: 249/300, total loss:0.0046\n",
      "Epoch 54/100, Step: 299/300, total loss:0.0036\n",
      "Epoch 54, accuracy: 0.9783, validation loss: 0.0107\n",
      "Epoch 55/100, Step: 49/300, total loss:0.0033\n",
      "Epoch 55/100, Step: 99/300, total loss:0.0033\n",
      "Epoch 55/100, Step: 149/300, total loss:0.0031\n",
      "Epoch 55/100, Step: 199/300, total loss:0.0028\n",
      "Epoch 55/100, Step: 249/300, total loss:0.0028\n",
      "Epoch 55/100, Step: 299/300, total loss:0.0027\n",
      "Epoch 55, accuracy: 0.9783, validation loss: 0.0110\n",
      "Epoch 56/100, Step: 49/300, total loss:0.0024\n",
      "Epoch 56/100, Step: 99/300, total loss:0.0023\n",
      "Epoch 56/100, Step: 149/300, total loss:0.0023\n",
      "Epoch 56/100, Step: 199/300, total loss:0.0023\n",
      "Epoch 56/100, Step: 249/300, total loss:0.0021\n",
      "Epoch 56/100, Step: 299/300, total loss:0.0021\n",
      "Epoch 56, accuracy: 0.9783, validation loss: 0.0113\n",
      "Epoch 57/100, Step: 49/300, total loss:0.0021\n",
      "Epoch 57/100, Step: 99/300, total loss:0.0018\n",
      "Epoch 57/100, Step: 149/300, total loss:0.0018\n",
      "Epoch 57/100, Step: 199/300, total loss:0.0017\n",
      "Epoch 57/100, Step: 249/300, total loss:0.1767\n",
      "Epoch 57/100, Step: 299/300, total loss:1.8976\n",
      "Epoch 57, accuracy: 0.9758, validation loss: 0.0080\n",
      "Epoch 58/100, Step: 49/300, total loss:0.4971\n",
      "Epoch 58/100, Step: 99/300, total loss:0.0153\n",
      "Epoch 58/100, Step: 149/300, total loss:1.2922\n",
      "Epoch 58/100, Step: 199/300, total loss:0.2715\n",
      "Epoch 58/100, Step: 249/300, total loss:0.2259\n",
      "Epoch 58/100, Step: 299/300, total loss:1.3682\n",
      "Epoch 58, accuracy: 0.9717, validation loss: 0.0075\n",
      "Epoch 59/100, Step: 49/300, total loss:0.5757\n",
      "Epoch 59/100, Step: 99/300, total loss:0.1130\n",
      "Epoch 59/100, Step: 149/300, total loss:0.0091\n",
      "Epoch 59/100, Step: 199/300, total loss:0.0079\n",
      "Epoch 59/100, Step: 249/300, total loss:0.0625\n",
      "Epoch 59/100, Step: 299/300, total loss:0.8198\n",
      "Epoch 59, accuracy: 0.9717, validation loss: 0.0134\n",
      "Epoch 60/100, Step: 49/300, total loss:0.1307\n",
      "Epoch 60/100, Step: 99/300, total loss:0.4155\n",
      "Epoch 60/100, Step: 149/300, total loss:0.2348\n",
      "Epoch 60/100, Step: 199/300, total loss:0.1300\n",
      "Epoch 60/100, Step: 249/300, total loss:0.9168\n",
      "Epoch 60/100, Step: 299/300, total loss:0.2599\n",
      "Epoch 60, accuracy: 0.9525, validation loss: 0.0181\n",
      "Epoch 61/100, Step: 49/300, total loss:0.4332\n",
      "Epoch 61/100, Step: 99/300, total loss:0.2234\n",
      "Epoch 61/100, Step: 149/300, total loss:0.0473\n",
      "Epoch 61/100, Step: 199/300, total loss:0.0806\n",
      "Epoch 61/100, Step: 249/300, total loss:0.0459\n",
      "Epoch 61/100, Step: 299/300, total loss:0.0333\n",
      "Epoch 61, accuracy: 0.9750, validation loss: 0.0086\n",
      "Epoch 62/100, Step: 49/300, total loss:0.0042\n",
      "Epoch 62/100, Step: 99/300, total loss:0.0041\n",
      "Epoch 62/100, Step: 149/300, total loss:0.0037\n",
      "Epoch 62/100, Step: 199/300, total loss:0.0033\n",
      "Epoch 62/100, Step: 249/300, total loss:0.0036\n",
      "Epoch 62/100, Step: 299/300, total loss:0.0030\n",
      "Epoch 62, accuracy: 0.9758, validation loss: 0.0089\n",
      "Epoch 63/100, Step: 49/300, total loss:0.0027\n",
      "Epoch 63/100, Step: 99/300, total loss:0.0187\n",
      "Epoch 63/100, Step: 149/300, total loss:0.0029\n",
      "Epoch 63/100, Step: 199/300, total loss:0.0023\n",
      "Epoch 63/100, Step: 249/300, total loss:0.0026\n",
      "Epoch 63/100, Step: 299/300, total loss:0.0021\n",
      "Epoch 63, accuracy: 0.9758, validation loss: 0.0118\n",
      "Epoch 64/100, Step: 49/300, total loss:0.0019\n",
      "Epoch 64/100, Step: 99/300, total loss:0.0034\n",
      "Epoch 64/100, Step: 149/300, total loss:0.0017\n",
      "Epoch 64/100, Step: 199/300, total loss:0.0016\n",
      "Epoch 64/100, Step: 249/300, total loss:0.0315\n",
      "Epoch 64/100, Step: 299/300, total loss:0.0016\n",
      "Epoch 64, accuracy: 0.9808, validation loss: 0.0091\n",
      "Epoch 65/100, Step: 49/300, total loss:0.0046\n",
      "Epoch 65/100, Step: 99/300, total loss:0.0014\n",
      "Epoch 65/100, Step: 149/300, total loss:0.0013\n",
      "Epoch 65/100, Step: 199/300, total loss:0.0013\n",
      "Epoch 65/100, Step: 249/300, total loss:0.0012\n",
      "Epoch 65/100, Step: 299/300, total loss:0.0011\n",
      "Epoch 65, accuracy: 0.9775, validation loss: 0.0108\n",
      "Epoch 66/100, Step: 49/300, total loss:0.0011\n",
      "Epoch 66/100, Step: 99/300, total loss:0.0011\n",
      "Epoch 66/100, Step: 149/300, total loss:0.0010\n",
      "Epoch 66/100, Step: 199/300, total loss:0.0010\n",
      "Epoch 66/100, Step: 249/300, total loss:0.0010\n",
      "Epoch 66/100, Step: 299/300, total loss:0.0009\n",
      "Epoch 66, accuracy: 0.9775, validation loss: 0.0110\n",
      "Epoch 67/100, Step: 49/300, total loss:0.0009\n",
      "Epoch 67/100, Step: 99/300, total loss:0.0009\n",
      "Epoch 67/100, Step: 149/300, total loss:0.0009\n",
      "Epoch 67/100, Step: 199/300, total loss:0.0009\n",
      "Epoch 67/100, Step: 249/300, total loss:0.0008\n",
      "Epoch 67/100, Step: 299/300, total loss:0.0008\n",
      "Epoch 67, accuracy: 0.9775, validation loss: 0.0112\n",
      "Epoch 68/100, Step: 49/300, total loss:0.0008\n",
      "Epoch 68/100, Step: 99/300, total loss:0.0007\n",
      "Epoch 68/100, Step: 149/300, total loss:0.0007\n",
      "Epoch 68/100, Step: 199/300, total loss:0.0007\n",
      "Epoch 68/100, Step: 249/300, total loss:0.0007\n",
      "Epoch 68/100, Step: 299/300, total loss:0.0007\n",
      "Epoch 68, accuracy: 0.9783, validation loss: 0.0115\n",
      "Epoch 69/100, Step: 49/300, total loss:0.0006\n",
      "Epoch 69/100, Step: 99/300, total loss:0.0006\n",
      "Epoch 69/100, Step: 149/300, total loss:0.0006\n",
      "Epoch 69/100, Step: 199/300, total loss:0.1008\n",
      "Epoch 69/100, Step: 249/300, total loss:2.0324\n",
      "Epoch 69/100, Step: 299/300, total loss:1.2616\n",
      "Epoch 69, accuracy: 0.9742, validation loss: 0.0086\n",
      "Epoch 70/100, Step: 49/300, total loss:0.6758\n",
      "Epoch 70/100, Step: 99/300, total loss:0.1749\n",
      "Epoch 70/100, Step: 149/300, total loss:0.0354\n",
      "Epoch 70/100, Step: 199/300, total loss:0.2709\n",
      "Epoch 70/100, Step: 249/300, total loss:0.2153\n",
      "Epoch 70/100, Step: 299/300, total loss:0.0932\n",
      "Epoch 70, accuracy: 0.9725, validation loss: 0.0130\n",
      "Epoch 71/100, Step: 49/300, total loss:0.5922\n",
      "Epoch 71/100, Step: 99/300, total loss:0.0182\n",
      "Epoch 71/100, Step: 149/300, total loss:0.0103\n",
      "Epoch 71/100, Step: 199/300, total loss:0.5409\n",
      "Epoch 71/100, Step: 249/300, total loss:0.7303\n",
      "Epoch 71/100, Step: 299/300, total loss:0.0653\n",
      "Epoch 71, accuracy: 0.9750, validation loss: 0.0091\n",
      "Epoch 72/100, Step: 49/300, total loss:0.0127\n",
      "Epoch 72/100, Step: 99/300, total loss:0.0097\n",
      "Epoch 72/100, Step: 149/300, total loss:0.0078\n",
      "Epoch 72/100, Step: 199/300, total loss:0.0069\n",
      "Epoch 72/100, Step: 249/300, total loss:0.0060\n",
      "Epoch 72/100, Step: 299/300, total loss:0.0052\n",
      "Epoch 72, accuracy: 0.9758, validation loss: 0.0094\n",
      "Epoch 73/100, Step: 49/300, total loss:0.0045\n",
      "Epoch 73/100, Step: 99/300, total loss:0.1805\n",
      "Epoch 73/100, Step: 149/300, total loss:0.6523\n",
      "Epoch 73/100, Step: 199/300, total loss:0.0785\n",
      "Epoch 73/100, Step: 249/300, total loss:0.0105\n",
      "Epoch 73/100, Step: 299/300, total loss:0.0102\n",
      "Epoch 73, accuracy: 0.9808, validation loss: 0.0072\n",
      "Epoch 74/100, Step: 49/300, total loss:0.0060\n",
      "Epoch 74/100, Step: 99/300, total loss:0.0055\n",
      "Epoch 74/100, Step: 149/300, total loss:0.0046\n",
      "Epoch 74/100, Step: 199/300, total loss:0.0043\n",
      "Epoch 74/100, Step: 249/300, total loss:0.0042\n",
      "Epoch 74/100, Step: 299/300, total loss:0.0036\n",
      "Epoch 74, accuracy: 0.9783, validation loss: 0.0081\n",
      "Epoch 75/100, Step: 49/300, total loss:0.0033\n",
      "Epoch 75/100, Step: 99/300, total loss:0.0032\n",
      "Epoch 75/100, Step: 149/300, total loss:0.0028\n",
      "Epoch 75/100, Step: 199/300, total loss:0.0027\n",
      "Epoch 75/100, Step: 249/300, total loss:0.0028\n",
      "Epoch 75/100, Step: 299/300, total loss:0.0024\n",
      "Epoch 75, accuracy: 0.9800, validation loss: 0.0087\n",
      "Epoch 76/100, Step: 49/300, total loss:0.0022\n",
      "Epoch 76/100, Step: 99/300, total loss:0.0022\n",
      "Epoch 76/100, Step: 149/300, total loss:0.0020\n",
      "Epoch 76/100, Step: 199/300, total loss:0.0019\n",
      "Epoch 76/100, Step: 249/300, total loss:0.0018\n",
      "Epoch 76/100, Step: 299/300, total loss:0.0018\n",
      "Epoch 76, accuracy: 0.9800, validation loss: 0.0090\n",
      "Epoch 77/100, Step: 49/300, total loss:0.0017\n",
      "Epoch 77/100, Step: 99/300, total loss:0.7197\n",
      "Epoch 77/100, Step: 149/300, total loss:0.0174\n",
      "Epoch 77/100, Step: 199/300, total loss:1.9700\n",
      "Epoch 77/100, Step: 249/300, total loss:0.6211\n",
      "Epoch 77/100, Step: 299/300, total loss:0.3504\n",
      "Epoch 77, accuracy: 0.9767, validation loss: 0.0067\n",
      "Epoch 78/100, Step: 49/300, total loss:0.0926\n",
      "Epoch 78/100, Step: 99/300, total loss:0.5831\n",
      "Epoch 78/100, Step: 149/300, total loss:0.0719\n",
      "Epoch 78/100, Step: 199/300, total loss:1.0032\n",
      "Epoch 78/100, Step: 249/300, total loss:0.0309\n",
      "Epoch 78/100, Step: 299/300, total loss:0.0299\n",
      "Epoch 78, accuracy: 0.9758, validation loss: 0.0121\n",
      "Epoch 79/100, Step: 49/300, total loss:0.0068\n",
      "Epoch 79/100, Step: 99/300, total loss:0.5599\n",
      "Epoch 79/100, Step: 149/300, total loss:0.0139\n",
      "Epoch 79/100, Step: 199/300, total loss:0.4824\n",
      "Epoch 79/100, Step: 249/300, total loss:0.0304\n",
      "Epoch 79/100, Step: 299/300, total loss:0.0131\n",
      "Epoch 79, accuracy: 0.9750, validation loss: 0.0091\n",
      "Epoch 80/100, Step: 49/300, total loss:0.0121\n",
      "Epoch 80/100, Step: 99/300, total loss:0.1316\n",
      "Epoch 80/100, Step: 149/300, total loss:0.4839\n",
      "Epoch 80/100, Step: 199/300, total loss:0.4938\n",
      "Epoch 80/100, Step: 249/300, total loss:0.0120\n",
      "Epoch 80/100, Step: 299/300, total loss:0.0070\n",
      "Epoch 80, accuracy: 0.9733, validation loss: 0.0122\n",
      "Epoch 81/100, Step: 49/300, total loss:0.0050\n",
      "Epoch 81/100, Step: 99/300, total loss:0.0043\n",
      "Epoch 81/100, Step: 149/300, total loss:0.0037\n",
      "Epoch 81/100, Step: 199/300, total loss:0.5777\n",
      "Epoch 81/100, Step: 249/300, total loss:0.0147\n",
      "Epoch 81/100, Step: 299/300, total loss:0.0205\n",
      "Epoch 81, accuracy: 0.9733, validation loss: 0.0117\n",
      "Epoch 82/100, Step: 49/300, total loss:0.0071\n",
      "Epoch 82/100, Step: 99/300, total loss:0.0058\n",
      "Epoch 82/100, Step: 149/300, total loss:0.0050\n",
      "Epoch 82/100, Step: 199/300, total loss:0.0048\n",
      "Epoch 82/100, Step: 249/300, total loss:1.2013\n",
      "Epoch 82/100, Step: 299/300, total loss:0.0923\n",
      "Epoch 82, accuracy: 0.9742, validation loss: 0.0107\n",
      "Epoch 83/100, Step: 49/300, total loss:0.0137\n",
      "Epoch 83/100, Step: 99/300, total loss:0.5065\n",
      "Epoch 83/100, Step: 149/300, total loss:0.0321\n",
      "Epoch 83/100, Step: 199/300, total loss:0.0163\n",
      "Epoch 83/100, Step: 249/300, total loss:0.0105\n",
      "Epoch 83/100, Step: 299/300, total loss:0.0084\n",
      "Epoch 83, accuracy: 0.9733, validation loss: 0.0116\n",
      "Epoch 84/100, Step: 49/300, total loss:0.0075\n",
      "Epoch 84/100, Step: 99/300, total loss:0.4404\n",
      "Epoch 84/100, Step: 149/300, total loss:0.0126\n",
      "Epoch 84/100, Step: 199/300, total loss:0.0089\n",
      "Epoch 84/100, Step: 249/300, total loss:0.0119\n",
      "Epoch 84/100, Step: 299/300, total loss:0.0059\n",
      "Epoch 84, accuracy: 0.9725, validation loss: 0.0120\n",
      "Epoch 85/100, Step: 49/300, total loss:0.0053\n",
      "Epoch 85/100, Step: 99/300, total loss:0.0047\n",
      "Epoch 85/100, Step: 149/300, total loss:0.0044\n",
      "Epoch 85/100, Step: 199/300, total loss:0.0038\n",
      "Epoch 85/100, Step: 249/300, total loss:0.0036\n",
      "Epoch 85/100, Step: 299/300, total loss:0.5371\n",
      "Epoch 85, accuracy: 0.9692, validation loss: 0.0120\n",
      "Epoch 86/100, Step: 49/300, total loss:0.0155\n",
      "Epoch 86/100, Step: 99/300, total loss:0.0111\n",
      "Epoch 86/100, Step: 149/300, total loss:0.0060\n",
      "Epoch 86/100, Step: 199/300, total loss:0.0042\n",
      "Epoch 86/100, Step: 249/300, total loss:0.0035\n",
      "Epoch 86/100, Step: 299/300, total loss:0.0042\n",
      "Epoch 86, accuracy: 0.9725, validation loss: 0.0124\n",
      "Epoch 87/100, Step: 49/300, total loss:0.0045\n",
      "Epoch 87/100, Step: 99/300, total loss:0.0026\n",
      "Epoch 87/100, Step: 149/300, total loss:0.0028\n",
      "Epoch 87/100, Step: 199/300, total loss:0.0023\n",
      "Epoch 87/100, Step: 249/300, total loss:0.0021\n",
      "Epoch 87/100, Step: 299/300, total loss:0.0176\n",
      "Epoch 87, accuracy: 0.9733, validation loss: 0.0136\n",
      "Epoch 88/100, Step: 49/300, total loss:0.0018\n",
      "Epoch 88/100, Step: 99/300, total loss:0.0035\n",
      "Epoch 88/100, Step: 149/300, total loss:0.0016\n",
      "Epoch 88/100, Step: 199/300, total loss:0.0015\n",
      "Epoch 88/100, Step: 249/300, total loss:0.0014\n",
      "Epoch 88/100, Step: 299/300, total loss:0.0014\n",
      "Epoch 88, accuracy: 0.9750, validation loss: 0.0146\n",
      "Epoch 89/100, Step: 49/300, total loss:0.0013\n",
      "Epoch 89/100, Step: 99/300, total loss:0.0012\n",
      "Epoch 89/100, Step: 149/300, total loss:0.0012\n",
      "Epoch 89/100, Step: 199/300, total loss:0.0011\n",
      "Epoch 89/100, Step: 249/300, total loss:0.0011\n",
      "Epoch 89/100, Step: 299/300, total loss:0.0010\n",
      "Epoch 89, accuracy: 0.9750, validation loss: 0.0150\n",
      "Epoch 90/100, Step: 49/300, total loss:0.0010\n",
      "Epoch 90/100, Step: 99/300, total loss:0.0009\n",
      "Epoch 90/100, Step: 149/300, total loss:0.0009\n",
      "Epoch 90/100, Step: 199/300, total loss:0.0009\n",
      "Epoch 90/100, Step: 249/300, total loss:0.0008\n",
      "Epoch 90/100, Step: 299/300, total loss:0.0008\n",
      "Epoch 90, accuracy: 0.9750, validation loss: 0.0154\n",
      "Epoch 91/100, Step: 49/300, total loss:0.0008\n",
      "Epoch 91/100, Step: 99/300, total loss:0.0007\n",
      "Epoch 91/100, Step: 149/300, total loss:0.0007\n",
      "Epoch 91/100, Step: 199/300, total loss:0.0007\n",
      "Epoch 91/100, Step: 249/300, total loss:0.0006\n",
      "Epoch 91/100, Step: 299/300, total loss:0.0006\n",
      "Epoch 91, accuracy: 0.9750, validation loss: 0.0157\n",
      "Epoch 92/100, Step: 49/300, total loss:0.0006\n",
      "Epoch 92/100, Step: 99/300, total loss:0.0006\n",
      "Epoch 92/100, Step: 149/300, total loss:0.0006\n",
      "Epoch 92/100, Step: 199/300, total loss:0.0005\n",
      "Epoch 92/100, Step: 249/300, total loss:0.0005\n",
      "Epoch 92/100, Step: 299/300, total loss:0.0005\n",
      "Epoch 92, accuracy: 0.9750, validation loss: 0.0161\n",
      "Epoch 93/100, Step: 49/300, total loss:0.0005\n",
      "Epoch 93/100, Step: 99/300, total loss:0.0005\n",
      "Epoch 93/100, Step: 149/300, total loss:0.0004\n",
      "Epoch 93/100, Step: 199/300, total loss:0.0004\n",
      "Epoch 93/100, Step: 249/300, total loss:0.0004\n",
      "Epoch 93/100, Step: 299/300, total loss:0.0004\n",
      "Epoch 93, accuracy: 0.9750, validation loss: 0.0164\n",
      "Epoch 94/100, Step: 49/300, total loss:0.0004\n",
      "Epoch 94/100, Step: 99/300, total loss:0.0004\n",
      "Epoch 94/100, Step: 149/300, total loss:0.0004\n",
      "Epoch 94/100, Step: 199/300, total loss:0.0003\n",
      "Epoch 94/100, Step: 249/300, total loss:0.0003\n",
      "Epoch 94/100, Step: 299/300, total loss:0.0003\n",
      "Epoch 94, accuracy: 0.9750, validation loss: 0.0167\n",
      "Epoch 95/100, Step: 49/300, total loss:0.0003\n",
      "Epoch 95/100, Step: 99/300, total loss:0.0003\n",
      "Epoch 95/100, Step: 149/300, total loss:0.2325\n",
      "Epoch 95/100, Step: 199/300, total loss:2.6617\n",
      "Epoch 95/100, Step: 249/300, total loss:2.9911\n",
      "Epoch 95/100, Step: 299/300, total loss:2.2675\n",
      "Epoch 95, accuracy: 0.9675, validation loss: 0.0151\n",
      "Epoch 96/100, Step: 49/300, total loss:0.9689\n",
      "Epoch 96/100, Step: 99/300, total loss:0.1196\n",
      "Epoch 96/100, Step: 149/300, total loss:0.2570\n",
      "Epoch 96/100, Step: 199/300, total loss:0.1798\n",
      "Epoch 96/100, Step: 249/300, total loss:0.4603\n",
      "Epoch 96/100, Step: 299/300, total loss:0.0157\n",
      "Epoch 96, accuracy: 0.9758, validation loss: 0.0111\n",
      "Epoch 97/100, Step: 49/300, total loss:0.6583\n",
      "Epoch 97/100, Step: 99/300, total loss:0.0086\n",
      "Epoch 97/100, Step: 149/300, total loss:0.5127\n",
      "Epoch 97/100, Step: 199/300, total loss:0.0167\n",
      "Epoch 97/100, Step: 249/300, total loss:0.0072\n",
      "Epoch 97/100, Step: 299/300, total loss:0.0258\n",
      "Epoch 97, accuracy: 0.9758, validation loss: 0.0119\n",
      "Epoch 98/100, Step: 49/300, total loss:0.0055\n",
      "Epoch 98/100, Step: 99/300, total loss:0.0044\n",
      "Epoch 98/100, Step: 149/300, total loss:0.0038\n",
      "Epoch 98/100, Step: 199/300, total loss:0.4453\n",
      "Epoch 98/100, Step: 249/300, total loss:0.0121\n",
      "Epoch 98/100, Step: 299/300, total loss:0.0297\n",
      "Epoch 98, accuracy: 0.9750, validation loss: 0.0113\n",
      "Epoch 99/100, Step: 49/300, total loss:0.0044\n",
      "Epoch 99/100, Step: 99/300, total loss:0.0036\n",
      "Epoch 99/100, Step: 149/300, total loss:0.0037\n",
      "Epoch 99/100, Step: 199/300, total loss:0.0051\n",
      "Epoch 99/100, Step: 249/300, total loss:0.0028\n",
      "Epoch 99/100, Step: 299/300, total loss:0.0027\n",
      "Epoch 99, accuracy: 0.9750, validation loss: 0.0122\n",
      "Epoch 100/100, Step: 49/300, total loss:0.0025\n",
      "Epoch 100/100, Step: 99/300, total loss:0.0026\n",
      "Epoch 100/100, Step: 149/300, total loss:0.0020\n",
      "Epoch 100/100, Step: 199/300, total loss:0.0024\n",
      "Epoch 100/100, Step: 249/300, total loss:0.0020\n",
      "Epoch 100/100, Step: 299/300, total loss:0.0015\n",
      "Epoch 100, accuracy: 0.9742, validation loss: 0.0127\n"
     ]
    }
   ],
   "source": [
    "# 首先将模型调成训练模式\n",
    "model.train()\n",
    "\n",
    "# 清空一下cuda缓存\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 定义几个变量，帮助打印loss\n",
    "total_loss = 0.\n",
    "# 记录步数\n",
    "step = 0\n",
    "\n",
    "# 记录在验证集上最好的准确率\n",
    "best_accuracy = 0\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # 从batch中拿到训练数据\n",
    "        inputs, targets = to_device(inputs), targets.to(device)\n",
    "        # 传入模型进行前向传递\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criteria(outputs.view(-1), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        step += 1\n",
    "\n",
    "        if step % log_per_step == 0:\n",
    "            print(\"Epoch {}/{}, Step: {}/{}, total loss:{:.4f}\".format(epoch+1, epochs, i, len(train_loader), total_loss))\n",
    "            total_loss = 0\n",
    "\n",
    "        del inputs, targets\n",
    "\n",
    "    # 一个epoch后，使用过验证集进行验证\n",
    "    accuracy, validation_loss = validate()\n",
    "    print(\"Epoch {}, accuracy: {:.4f}, validation loss: {:.4f}\".format(epoch+1, accuracy, validation_loss))\n",
    "    torch.save(model, model_dir / f\"model_{epoch}.pt\")\n",
    "\n",
    "    # 保存最好的模型\n",
    "    if accuracy > best_accuracy:\n",
    "        torch.save(model, model_dir / f\"model_best.pt\")\n",
    "        best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载最好的模型，然后进行测试集的预测\n",
    "model = torch.load('../output/bert_checkpoints/model_best.pt')\n",
    "model = model.eval()\n",
    "test_dataset = MyDataset('test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for inputs, ids in test_loader:\n",
    "    outputs = model(inputs.to(device))\n",
    "    outputs = (outputs >= 0.5).int().flatten().tolist()\n",
    "    ids = ids.tolist()\n",
    "    results = results + [(id, result) for result, id in zip(outputs, ids)]\n",
    "test_label = [pair[1] for pair in results]\n",
    "test_data['label'] = test_label\n",
    "test_data['Keywords'] = test_data['title'].fillna('')\n",
    "test_data[['uuid', 'Keywords', 'label']].to_csv('submit_task1.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('xclds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f1e55e74c766e763530812631a72120f1fc83c0fcf0b61c7a0638716cdefb0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
