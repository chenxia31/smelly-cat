{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次比赛的使用的通风机的数据主要来自于[open-source ventilator](https://www.kaggle.com/competitions/ventilator-pressure-prediction/data),数据的使用流程包括：第一个控制是0-100的连续变量，用于控制空气进行肺部的百分比（0关闭/1打开），第二个控制是否让空气排出（0关闭/1打开）\n",
    "id：全局时间标识符\n",
    "breath_id:全局呼吸时间步骤\n",
    "R：气道手限成都，越高的越难吹\n",
    "C：肺部顺从性，越高的越容易吹\n",
    "time_step：实际的时间戳\n",
    "u_in:吸气电磁阀的控制输入0-100\n",
    "u_oyt:探索性电磁阀的控制输入 0-1\n",
    "pressure：在探索回路中测量的气道压力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  breath_id   R   C  time_step       u_in  u_out   pressure\n",
      "0   1          1  20  50   0.000000   0.083334      0   5.837492\n",
      "1   2          1  20  50   0.033652  18.383041      0   5.907794\n",
      "2   3          1  20  50   0.067514  22.509278      0   7.876254\n",
      "3   4          1  20  50   0.101542  22.808822      0  11.742872\n",
      "4   5          1  20  50   0.135756  25.355850      0  12.234987\n",
      "   id  breath_id  R   C  time_step       u_in  u_out\n",
      "0   1          0  5  20   0.000000   0.000000      0\n",
      "1   2          0  5  20   0.031904   7.515046      0\n",
      "2   3          0  5  20   0.063827  14.651675      0\n",
      "3   4          0  5  20   0.095751  21.230610      0\n",
      "4   5          0  5  20   0.127644  26.320956      0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train data is:  (6036000, 8)\n",
      "The shape of test data is:  (4024000, 7)\n",
      "The different types of id are:  [      1       2       3 ... 6035998 6035999 6036000]\n",
      "The different types of breath id are:  [     1      2      3 ... 125743 125745 125749]\n"
     ]
    }
   ],
   "source": [
    "print('The shape of train data is: ', df_train.shape)\n",
    "print('The shape of test data is: ', df_test.shape)\n",
    "print('The different types of id are: ', df_train['id'].unique())\n",
    "print('The different types of breath id are: ', df_train['breath_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of breath id is:  [80 80 80 ... 80 80 80]\n"
     ]
    }
   ],
   "source": [
    "# 计算每个breath_id的长度\n",
    "breath_id_len = df_train.groupby('breath_id').size().values\n",
    "print('The length of breath id is: ', breath_id_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering...\n"
     ]
    }
   ],
   "source": [
    "print('Feature engineering...')\n",
    "mask = np.array(df_train['u_out']==0).reshape(-1,80)\n",
    "\n",
    "def add_feature(df):\n",
    "    # 累积呼吸的量\n",
    "    df['u_in_cumsum'] = df['u_in'].groupby(df['breath_id']).cumsum()\n",
    "    # 时间差\n",
    "    df['time_diff']=df['time_step'].diff()\n",
    "    df['time_diff'].fillna(0, inplace=True)\n",
    "    df['time_diff'].mask(df['time_diff']<0,0,inplace=True)\n",
    "\n",
    "    # 累积压力量\n",
    "    df['tmp']=df['u_in']*df['time_diff']\n",
    "    df['area_true']=df['tmp'].groupby(df['breath_id']).cumsum()\n",
    "    df['tmp'] = df['u_out']*(-1)+1\n",
    "\n",
    "add_feature(df_train)\n",
    "add_feature(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop the useless columns...\n"
     ]
    }
   ],
   "source": [
    "print('Drop the useless columns...')\n",
    "targets = df_train[['pressure']].to_numpy()\n",
    "df_train.drop(['id', 'breath_id', 'pressure'], axis=1, inplace=True)\n",
    "df_test.drop(['id', 'breath_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize the data...\n"
     ]
    }
   ],
   "source": [
    "print('Normalize the data...')\n",
    "from sklearn.preprocessing import RobustScaler,normalize\n",
    "RS = RobustScaler()\n",
    "df_train = RS.fit_transform(df_train)\n",
    "df_test = RS.transform(df_test)\n",
    "\n",
    "df_train = df_train.reshape(-1,80,df_train.shape[1])\n",
    "df_test = df_test.reshape(-1,80,df_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K fold...\n",
      "Build the dataset...\n",
      "The shape of train features is:  (60360, 80, 9)\n"
     ]
    }
   ],
   "source": [
    "print('K fold...')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2021)\n",
    "\n",
    "train_features =[df_train[i] for i in list(kf.split(df_train))[0][0]]\n",
    "train_targets =[targets[i] for i in list(kf.split(df_train))[0][0]]\n",
    "val_features =[df_train[i] for i in list(kf.split(df_train))[0][1]]\n",
    "val_targets =[targets[i] for i in list(kf.split(df_train))[0][1]]\n",
    "train_mask =[mask[i] for i in list(kf.split(df_train))[0][0]]\n",
    "val_mask =[mask[i] for i in list(kf.split(df_train))[0][1]]\n",
    "\n",
    "print('Build the dataset...')\n",
    "print('The shape of train features is: ', np.array(train_features).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the dataloader...\n"
     ]
    }
   ],
   "source": [
    "print('Create the dataloader...')\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "bacth_size = 256\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, targets, mask):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.mask = mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index].astype('float32'),\n",
    "        self.targets[index].astype('float32'),\n",
    "        self.mask[index].astype('bool')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, features, mask):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.features = features\n",
    "        self.mask = mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index].astype('float32'),self.mask[index].astype('bool')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "train_dataset = MyDataset(train_features, train_targets, train_mask)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bacth_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = MyDataset(val_features, val_targets, val_mask)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bacth_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_targets = torch.tensor(train_targets, dtype=torch.float32)\n",
    "train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "val_features = torch.tensor(val_features, dtype=torch.float32)\n",
    "val_targets = torch.tensor(val_targets, dtype=torch.float32)\n",
    "val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_targets, train_mask)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bacth_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(val_features, val_targets, val_mask)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bacth_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RedisualLSTM(nn.Module):\n",
    "    def __init__(self,d_model):\n",
    "        super().__init__()\n",
    "        self.LSTM = nn.LSTM(d_model, d_model, num_layers=2, bidirectional=True)\n",
    "        self.linear = nn.Linear(d_model*2, d_model*4)\n",
    "        self.linear2 = nn.Linear(d_model*4, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x, _ = self.LSTM(x)\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "        x = x + res\n",
    "        return x\n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(self,n_skill,n_cat,nout,max_seq=100,embed_dim=128,pos_encode='LSTM',nlayers=2,rnnlayers=3,dropout=0.1,nheads=8):\n",
    "        super().__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "        if pos_encode == 'LSTM':\n",
    "            self.pos_encoder = nn.ModuleList([RedisualLSTM(embed_dim) for _ in range(nlayers)])\n",
    "        \n",
    "        self.pos_encoder_dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Linear(n_skill, embed_dim)\n",
    "        self.cat_embedding = nn.Embedding(n_cat, embed_dim,padding_idx=0)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        encoder_layer =[nn.TransformerEncoderLayer(embed_dim, nheads,embed_dim*4 ,dropout) for _ in range(nlayers)]\n",
    "        conv_layer = [nn.Conv1d(embed_dim,embed_dim,(nlayers-1)*2-1,stride=1,padding=0) for _ in range(nlayers)]\n",
    "        deconv_layers = [nn.ConvTranspose1d(embed_dim,embed_dim,(nlayers-1)*2-1,stride=1,padding=0) for _ in range(nlayers)]\n",
    "\n",
    "        layer_norm_layers = [nn.LayerNorm(embed_dim) for _ in range(nlayers)]\n",
    "        layer_norm_layers2 = [nn.LayerNorm(embed_dim) for _ in range(nlayers)]\n",
    "\n",
    "        self.transformer_encoder = nn.ModuleList(encoder_layer)\n",
    "        self.conv = nn.ModuleList(conv_layer)\n",
    "        self.deconv = nn.ModuleList(deconv_layers)\n",
    "        self.layer_norm = nn.ModuleList(layer_norm_layers)\n",
    "        self.layer_norm2 = nn.ModuleList(layer_norm_layers2)\n",
    "        self.nhead = nheads\n",
    "        self.pred = nn.Linear(embed_dim, nout)\n",
    "        self.downsample = nn.Linear(embed_dim*2, embed_dim)\n",
    "    \n",
    "    def forward(self, x, cat=None):\n",
    "        device = x.device\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1,0,2) # ?什么意思 为什么要转置\n",
    "        for lstm in self.pos_encoder:\n",
    "            lstm.LSTM.flatten_parameters()\n",
    "            x= lstm(x)\n",
    "        x = self.pos_encoder_dropout(x)\n",
    "        x = self.layer_norm(x)\n",
    "        for conv,transformer_layer,layer_norm,layer_norm2,deconv in zip(self.conv,self.transformer_encoder,self.layer_norm,self.layer_norm2,self.deconv):\n",
    "            # LXBXC -> BXCXL\n",
    "            res = x\n",
    "            x = F.relu(conv(x.permute(1,2,0)).permute(2,0,1))\n",
    "            x = layer_norm(x)\n",
    "            x= F.relu(deconv(x.permute(1,2,0)).permute(2,0,1))\n",
    "            x = layer_norm2(x)\n",
    "            x = res + x\n",
    "        x = x.permute(1,0,2)\n",
    "        output = self.pred(x)\n",
    "        return output.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAKTModel(n_skill=df_train.shape[-1],n_cat=10,nout=1,max_seq=None,embed_dim=256,pos_encode='LSTM',nlayers=2,rnnlayers=3,dropout=0.1,nheads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb Cell 15\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m best_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minf\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train_epoch(mdoel,train_loader,optimizer,criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     val_loss, preds \u001b[39m=\u001b[39m val_epoch(mdoel,val_loader,criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch - \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m train_loss - \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m val_loss - \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39;49mforward(x)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y)\n",
      "\u001b[1;32m/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb Cell 15\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     x\u001b[39m=\u001b[39m lstm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder_dropout(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_norm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mfor\u001b[39;00m conv,transformer_layer,layer_norm,layer_norm2,deconv \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm2,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeconv):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39m# LXBXC -> BXCXL\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.16.2.243/home/step/data/python-smelly-cat/zoo_kaggle/GoogleBrain/notebook/explor.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     res \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/anaconda3/envs/xclds/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/xclds/lib/python3.9/site-packages/torch/nn/modules/module.py:363\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "from pytorch_ranger import Ranger\n",
    "optimizer = Ranger(mdoel.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "import tqdm\n",
    "\n",
    "def train_epoch(model,train_loader,optimizer,criterion):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for (x,y,mask) in train_loader:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        mask = mask.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        print(model.forward(x).shape)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        bar.set_description(f'loss - {loss.item():.5f}')\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def val_epoch(model,val_loader,criterion):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds = []\n",
    "    bar = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for (x,y,mask) in bar:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            mask = mask.cuda()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            val_loss.append(loss.item())\n",
    "            preds.append(output.sigmoid().detach().cpu().numpy())\n",
    "            bar.set_description(f'loss - {loss.item():.5f}')\n",
    "    val_loss = np.mean(val_loss)\n",
    "    preds = np.concatenate(preds)\n",
    "    return val_loss, preds\n",
    "\n",
    "epochs = 20\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(mdoel,train_loader,optimizer,criterion)\n",
    "    val_loss, preds = val_epoch(mdoel,val_loader,criterion)\n",
    "    print(f'epoch - {epoch + 1} train_loss - {train_loss:.5f} val_loss - {val_loss:.5f}')\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(mdoel.state_dict(), 'best_model.pt')\n",
    "\n",
    "print('Predict...')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
