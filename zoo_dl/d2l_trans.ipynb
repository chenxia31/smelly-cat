{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 32\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "num_steps = 10\n",
    "lr = 0.005\n",
    "num_epochs = 200\n",
    "device = d2l.try_gpu()\n",
    "train_iter,src_vocab,tgt_vocab = d2l.load_data_nmt(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n",
      "184\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "for x in train_iter:\n",
    "    print(x[0].shape) # src sentence\n",
    "    print(x[1].shape) # valid length\n",
    "    print(x[2].shape) # tgt sentence\n",
    "    print(x[3].shape) # valid length\n",
    "    break\n",
    "print(len(src_vocab))\n",
    "print(len(tgt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math \n",
    "device = torch.device('cpu')\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size,embedding_size) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.embedding_size = embedding_size\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.embedding(x.long())*math.sqrt(self.embedding_size)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,dimen,dropout=0.1,max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        PE = torch.zeros(max_len,dimen)\n",
    "        position = torch.arange(0,max_len,dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,dimen,2).float() * (-math.log(10000.0) / dimen))\n",
    "        PE[:,0::2] = torch.sin(position * div_term)\n",
    "        PE[:,1::2] = torch.cos(position * div_term)\n",
    "        PE = PE.unsqueeze(0).transpose(0,1)\n",
    "        self.register_buffer('PE',PE)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.PE[:x.size(0),:]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class seq2seqTrans(nn.Module):\n",
    "    def __init__(self,num_encoder_layers,num_decoder_layers,emb_size,nhead,src_vocab_size,tgt_vocab_size,dim_feedforward=512,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size,emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size,emb_size)\n",
    "\n",
    "        self.pos_emb = PositionalEncoding(emb_size,dropout)\n",
    "\n",
    "        self.transformer = Transformer(d_model=emb_size,nhead=nhead,num_encoder_layers=num_encoder_layers,num_decoder_layers=num_decoder_layers,dim_feedforward=dim_feedforward,dropout=dropout)\n",
    "        self.linear = nn.Linear(emb_size,tgt_vocab_size)\n",
    "    \n",
    "    def forward(self,src,tgt,src_mask,tgt_mask,src_padding_mask,tgt_padding_mask,src_key_padding_mask,tgt_key_padding_mask,memory_key_padding_mask):\n",
    "        src_emb = self.pos_emb(self.src_tok_emb(src))\n",
    "\n",
    "        tgt_emb = self.pos_emb(self.tgt_tok_emb(tgt))\n",
    "        memory = self.transformer(src_emb,tgt_emb,src_mask,tgt_mask,None,src_key_padding_mask,tgt_key_padding_mask,memory_key_padding_mask)\n",
    "        return self.linear(memory)\n",
    "    \n",
    "    def encode(self,src,src_mask):\n",
    "        return self.transformer.encoder(self.pos_emb(self.src_tok_emb(src)),src_mask)\n",
    "    \n",
    "    def decode(self,tgt,memory,tgt_mask):\n",
    "        return self.transformer.decoder(self.pos_emb(self.tgt_tok_emb(tgt)),memory,tgt_mask)\n",
    "\n",
    "\n",
    "\n",
    "model = seq2seqTrans(num_encoder_layers=num_layers,\n",
    "                     num_decoder_layers=num_layers,\n",
    "                     emb_size=num_hiddens,\n",
    "                     nhead=4,\n",
    "                     src_vocab_size=len(src_vocab),\n",
    "                     tgt_vocab_size=len(tgt_vocab),\n",
    "                     dim_feedforward=512,\n",
    "                     dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == src_vocab['<pad>']).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == tgt_vocab['<pad>']).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "attention to the mask when input the model for gradient decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=src_vocab['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([64, 10])\n",
      "tgt shape: torch.Size([64, 10])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([64, 10, 201])\n",
      "src shape: torch.Size([25, 10])\n",
      "tgt shape: torch.Size([25, 10])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([10, 25])\n",
      "torch.Size([10, 25])\n",
      "torch.Size([25, 10, 201])\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "from torch.utils.data import DataLoader as Dataloader\n",
    "for src,src_valid,tgt,tgt_valid in train_iter:\n",
    "    src.to(device)\n",
    "    tgt.to(device)\n",
    "    print('src shape:',src.shape)\n",
    "    print('tgt shape:',tgt.shape)\n",
    "    src_mask,tgt_mask,src_padding_mask,tgt_padding_mask = create_mask(src,tgt)\n",
    "    src_mask.to(device)\n",
    "    tgt_mask.to(device)\n",
    "    src_padding_mask.to(device)\n",
    "    tgt_padding_mask.to(device)\n",
    "    \n",
    "\n",
    "    print(src_mask.shape)\n",
    "    print(tgt_mask.shape)\n",
    "    print(src_padding_mask.shape)\n",
    "    print(tgt_padding_mask.shape)\n",
    "\n",
    "    logits = model(src,\n",
    "                   tgt,\n",
    "                   src_mask,\n",
    "                   tgt_mask,\n",
    "                   src_padding_mask,\n",
    "                   tgt_padding_mask,\n",
    "                   src_padding_mask,\n",
    "                   tgt_padding_mask,\n",
    "                   src_padding_mask)\n",
    "    print(logits.shape)\n",
    "    optimizer.zero_grad()\n",
    "    l = loss_fn(logits.reshape(-1,len(tgt_vocab)),tgt.reshape(-1))\n",
    "    l.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
