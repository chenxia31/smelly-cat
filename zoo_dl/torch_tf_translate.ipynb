{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sourcing and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,random_split\n",
    "import json\n",
    "\n",
    "class trans_data(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "\n",
    "    def load_data(self, data_file):\n",
    "        data = {}\n",
    "        with open(data_file, 'rt',encoding='utf-8') as f:\n",
    "            for idx,line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                sample = json.loads(line.strip())\n",
    "                data[idx] = sample\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "data = trans_data('../input/translation2019zh/translation2019zh_train.json')\n",
    "train_data,valid_data = random_split(data,[int(len(data)*0.9),len(data)-int(len(data)*0.9)])\n",
    "test_data = trans_data('../input/translation2019zh/translation2019zh_valid.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 4645290\n",
      "valid set size: 516144\n",
      "test set size: 39323\n",
      "{'english': 'Results of observation showed that applying the wax-chromium Replica technique to the transmission electron microscope was an effective way…', 'chinese': '观察结果说阴，用于透射电镜的复型技术是研究木材细胞壁表面形貌的一种具有高分辨率的有效方法。'}\n"
     ]
    }
   ],
   "source": [
    "print(f'train set size: {len(train_data)}')\n",
    "print(f'valid set size: {len(valid_data)}')\n",
    "print(f'test set size: {len(test_data)}')\n",
    "print(next(iter(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0x02 data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efc5533073e4ac6b56aa14905ff6774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc238acd32b49fc8d7f8dbe55d9a8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69849dd068f346ccb819b01736615259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/805k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59d0708883244749c1465a033bf8c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/807k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac24361fda14cedb1c3746fc2b7ce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/step/anaconda3/envs/xclds/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/home/step/anaconda3/envs/xclds/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3586: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer \n",
    "# Helsinki 提高多中文翻译模型\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "zh_sentence = train_data[0]['chinese']\n",
    "en_sentence = train_data[0]['english']\n",
    "\n",
    "input = tokenizer(zh_sentence)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    target = tokenizer(en_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([4, 31]), 'attention_mask': torch.Size([4, 31])}\n",
      "batch_y shape: torch.Size([4, 29])\n",
      "{'input_ids': tensor([[    7,  6215,  1686,   300, 17944,     2,  1022, 12556,  7233,  3534,\n",
      "         25472,    11,  7597,  3514,   653,    69,   751, 12835, 23293, 25483,\n",
      "         21603,  8054, 17021,  7130,   744,  1072, 42437,  7538,  1187,     9,\n",
      "             0],\n",
      "        [    7,  5583,  7262,    11, 14455, 43322, 13699, 25900,    11, 40144,\n",
      "         52319,    36,  4177, 29137, 47797,   188,  8181,  8223, 12072,  6534,\n",
      "         24238, 10154,     9,     0, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000],\n",
      "        [ 5233,    96, 23758,   454,  2923, 23011,  3410,   268,     7,  2658,\n",
      "          3094,     9,     0, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000],\n",
      "        [  335,  4718,   747, 12856,  1488,  4655, 62643,  8424, 11789,     9,\n",
      "             0, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "tensor([[22633,     4,  9552,  7152,    19,  8773,     3, 53817,    15,  3708,\n",
      "         23269, 10732, 41843, 15847,    86, 36951,     8,     3, 10131, 42655,\n",
      "           746,  9956, 37188,    42,    57,   429,   481,    68,     0],\n",
      "        [   24,  8472,    15, 58244,   210, 17911,  5579, 24174,    15, 24646,\n",
      "            10,  1167, 35866,   104, 33820,   293, 13687, 34148,   352,    15,\n",
      "           766,     6, 45619, 56545,     5,     0,  -100,  -100,  -100],\n",
      "        [  100,   122, 41641, 27627,   287, 10644,     8,   337, 44763,    22,\n",
      "             5,     0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "        [  140,  1177,    12,  7207,    15,  1843,   861,   129,  8470,  3599,\n",
      "             4,    56, 50849,     5,     0,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "inputs = [train_data[s_idx][\"chinese\"] for s_idx in range(4)]\n",
    "targets = [train_data[s_idx][\"english\"] for s_idx in range(4)]\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    inputs, \n",
    "    padding=True, \n",
    "    max_length=max_input_length, \n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(\n",
    "        targets, \n",
    "        padding=True, \n",
    "        max_length=max_target_length, \n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "end_token_index = torch.where(labels == tokenizer.eos_token_id)[1]\n",
    "for idx, end_idx in enumerate(end_token_index):\n",
    "    labels[idx][end_idx+1:] = -100\n",
    "\n",
    "print('batch_X shape:', {k: v.shape for k, v in model_inputs.items()})\n",
    "print('batch_y shape:', labels.shape)\n",
    "print(model_inputs)\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
