{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<START>': 0, '<STOP>': 1, 'Google': 2, 'Deepmind': 3, 'company': 4}\n",
      "tensor([2, 3, 4]) tensor([2, 3, 4])\n",
      "tensor([[ 0.1878,  0.0654,  0.4902,  0.1473, -0.1422],\n",
      "        [ 0.3721,  0.1898,  0.3060,  0.0743, -0.0744],\n",
      "        [ 0.2491,  0.0582,  0.4111,  0.1462, -0.1255]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([1.7896], grad_fn=<IndexBackward0>) tensor([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# LSTM-CRF forward model\n",
    "IMPOSSIBLE = -1e4\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, num_tags, start_tag, stop_tag,\n",
    "        embedding_dim, hidden_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tags = num_tags\n",
    "        self.START_TAG = start_tag\n",
    "        self.STOP_TAG = stop_tag\n",
    "            \n",
    "        # CRF parameters\n",
    "        self.transitions = nn.Parameter(torch.randn(self.num_tags, self.num_tags))\n",
    "            \n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[:, self.START_TAG] = IMPOSSIBLE\n",
    "        self.transitions.data[self.STOP_TAG, :] = IMPOSSIBLE\n",
    "\n",
    "        # LSTM parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True,\n",
    "                            batch_first=False)\n",
    "            \n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.num_tags)\n",
    "            \n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "        \n",
    "    def _get_emissions(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        return emissions\n",
    "        \n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        emissions = self._get_emissions(sentence)\n",
    "        forward_score = self._forward_alg(emissions)\n",
    "        gold_score = self._score_sentence(emissions, tags)\n",
    "        return forward_score - gold_score\n",
    "        \n",
    "    def _forward_alg(self, emissions):\n",
    "\n",
    "        init_alphas = self.transitions[self.START_TAG] + emissions[0]\n",
    "            \n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        alphas = init_alphas\n",
    "\n",
    "        for emission in emissions[1:]:\n",
    "            alphas_t = [] # The forward tensors at this timestep\n",
    "            for next_tag in range(self.num_tags):\n",
    "                # emission score for the next tag\n",
    "                emit_score = emission[next_tag].view(1, -1).expand(1, self.num_tags)\n",
    "                # transition score from any previous tag to the next tag\n",
    "                trans_score = self.transitions[:, next_tag].view(1, -1)\n",
    "                # combine current scores with previous alphas \n",
    "                # since alphas are in log space (see logsumexp below),\n",
    "                # we add them instead of multiplying\n",
    "                next_tag_var = alphas + trans_score + emit_score\n",
    "\n",
    "                alphas_t.append(torch.logsumexp(next_tag_var, 1).view(1))\n",
    "\n",
    "            alphas = torch.cat(alphas_t).view(1, -1)\n",
    "\n",
    "        terminal_alphas = alphas + self.transitions[:, self.STOP_TAG]\n",
    "        alphas = torch.logsumexp(terminal_alphas, 1)\n",
    "\n",
    "        return alphas\n",
    "    \n",
    "    def _viterbi_decode(self, emissions):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_alphas = self.transitions[self.START_TAG] + emissions[:1]\n",
    "\n",
    "        # alphas at step i holds the viterbi variables for step i-1\n",
    "        alphas = init_alphas\n",
    "        for emission in emissions[1:]:\n",
    "            bptrs_t = [] # holds the backpointers for this step\n",
    "            viterbivars_t = [] # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.num_tags):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = alphas + self.transitions[:, next_tag] + emission[next_tag]\n",
    "                best_tag_score, best_tag_id = torch.max(next_tag_var, dim=-1)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign alphas to the set\n",
    "            # of viterbi variables we just computed\n",
    "            alphas = (torch.cat(viterbivars_t)).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_alphas = alphas + self.transitions[:, self.STOP_TAG]\n",
    "        best_tag_score, best_tag_id = torch.max(terminal_alphas, dim=-1)\n",
    "        path_score = terminal_alphas[0][best_tag_id]\n",
    "            \n",
    "        # Follow the back pointers to decode the best path.\n",
    "        # Append terminal tag \n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "                \n",
    "        best_path.reverse()\n",
    "        best_path = torch.cat(best_path)\n",
    "            \n",
    "        return path_score, best_path\n",
    "\n",
    "    def forward(self, sentence): \n",
    "        # Get the emission scores from the BiLSTM\n",
    "        emissions = self._get_emissions(sentence)\n",
    "        print(emissions)\n",
    "\n",
    "        # Find the best path, given the emission scores.\n",
    "        score, tag_seq = self._viterbi_decode(emissions)\n",
    "        return score, tag_seq\n",
    "        \n",
    "    def _score_sentence(self, emissions, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.START_TAG], dtype=torch.long), tags[0]])\n",
    "        for i, emission in enumerate(emissions):\n",
    "            score = score + self.transitions[tags[i], tags[i+1]] + emission[tags[i+1]]\n",
    "        score = score + self.transitions[tags[-1], self.STOP_TAG]\n",
    "        return score\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    START_TAG = \"<START>\"\n",
    "    STOP_TAG = \"<STOP>\"\n",
    "    EMBEDDING_DIM = 5\n",
    "    HIDDEN_DIM = 4\n",
    "\n",
    "    training_data = [\n",
    "        (\n",
    "            \"Google Deepmind company\".split(), \n",
    "            \"B I O\".split(),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "    word_to_ix = {START_TAG: 0, STOP_TAG: 1}\n",
    "    for sentence, tags in training_data:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "    tag_to_ix = {START_TAG: 0, STOP_TAG: 1, 'B': 2, 'I': 3, 'O': 4}\n",
    "    print(word_to_ix)\n",
    "\n",
    "    crf_mod = BiLSTM_CRF(len(word_to_ix), len(tag_to_ix), tag_to_ix[START_TAG], tag_to_ix[STOP_TAG], \n",
    "                            embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "        \n",
    "        \n",
    "    sentence, tags = training_data[0]\n",
    "    sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "    targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    print(sentence_in, targets)\n",
    "        \n",
    "    score, tag_seq = crf_mod(sentence_in)\n",
    "    print(score, tag_seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
